---
title: 黑马点评
date: '2025-07-23 17:11:05'
updated: '2025-09-23 19:55:55'
categories:
  - JAVA
tags:
  - JAVA
  - 后端
cover: /images/custom-cover.jpg
recommend: true
---
## 项目介绍
主要完成功能为

![](/images/5539bc16f2510400584d3c6f13d381f7.png)

<font style="color:rgb(64, 62, 62);">架构图如下，前后端分离，开发完成后前后端分别部署在 Nginx 和 Tomcat 上。</font>

![](/images/4842f945f036a5b14d96b928727e437c.png)

## 项目导入
![](/images/fcf3d705d810b733cbb2aa6171d69906.png)

我采用的Java版本为JDK17

![](/images/82da093baf7c08a331c0a56a7e491f62.png)

项目编码为UTF-8

![](/images/3846518c693a173cbeb8881a86d36ed0.png)

前端项目代码已经放在了`<font style="color:rgb(199, 37, 78);background-color:rgb(249, 242, 244);">nginx-1.18.0/html</font>`

使用localhost:8080打开前端页面

后端搭建还是分3步:

1. 创建Springboot工程项目
2. pom文件导入依赖坐标
3. yml配置文件添加配置信息

整个架构就是用mybatis-plus做持久层，业务层，控制层，加上对应注解，调mp提供的api就完了，实体类这些更不用多说，按表映射成实体类。



## Postman接口测试
[黑马点评使用Apifox进行接口测试(以导入更新店铺为例、详细图解)_黑马点评项目的接口api文档-CSDN博客](https://blog.csdn.net/2301_80558092/article/details/149539580)



## Redis
Redis 的 Java 客户端很多，常用的几种：

+ Jedis
+ Lettuce
+ Spring Data Redis

Spring 对 Redis 客户端进行了整合，提供了 Spring Data Redis，在Spring Boot项目中还提供了对应的Starter，即 spring-boot-starter-data-redis。

**我们重点学习Spring Data Redis。**

### SpringDataRedis
`SpringData是Spring中数据操作的模块，包含对各种数据库的集成，其中对Redis的集成模块就叫做SpringDataRedis，官网地址：[https://spring.io/projects/spring-data-redis](https://spring.io/projects/spring-data-redis)

- 提供了对不同Redis客户端的整合（Lettuce和Jedis）

- 提供了RedisTemplate统一API来操作Redis

- 支持Redis的发布订阅模型

- 支持Redis哨兵和Redis集群

- 支持基于Lettuce的响应式编程

- 支持基于JDK、JSON、字符串、Spring对象的数据序列化及反序列化

- 支持基于Redis的JDKCollection实现`

#### 依赖:
```plain
<dependency>
	<groupId>org.springframework.boot</groupId>
	<artifactId>spring-boot-starter-data-redis</artifactId>
</dependency>

```

Spring Data Redis中提供了一个高度封装的类：**RedisTemplate**，对相关api进行了归类封装,将同一类型操作封装为operation接口，具体分类如下：

+ ValueOperations：string数据操作
+ SetOperations：set类型数据操作
+ ZSetOperations：zset类型数据操作
+ HashOperations：hash类型的数据操作
+ ListOperations：list类型的数据操作

#### 配置Redis数据源:
```plain
在application-dev.yml中添加
spring:
  redis:
    host: 192.168.150.101
    port: 6379
    password: 123321
    database: 0
    lettuce:
      pool:
        max-active: 8
        max-idle: 8
        min-idle: 0
        max-wait: 100ms


```

database:指定使用Redis的哪个数据库，Redis服务启动后默认有16个数据库，编号分别是从0到15。

可以通过修改Redis配置文件来指定数据库的数量

#### 注入RedisTemplate:
```plain
@SpringBootTest
class RedisStringTests {

    @Autowired
    private RedisTemplate redisTemplate;
}

```

### 自定义序列化:
**why?**

RedisTemplate可以接收任意Object作为值写入Redis

只不过写入前会把Object序列化为字节形式，默认是采用**<font style="color:#DF2A3F;">JDK序列化</font>**，得到的结果是这样的：

![](/images/4ff4bdef5627e70a14999bf771988a41.png)缺点：

    - 可读性差
    - 内存占用较大

#### 自定义RedisTemplate的序列化方式
**<font style="color:#DF2A3F;">josn序列化</font>**

```python
@Configuration
public class RedisConfig {

    @Bean
    public RedisTemplate<String, Object> redisTemplate(RedisConnectionFactory connectionFactory){
        // 创建RedisTemplate对象
        RedisTemplate<String, Object> template = new RedisTemplate<>();
        // 设置连接工厂
        template.setConnectionFactory(connectionFactory);
        // 创建JSON序列化工具
        GenericJackson2JsonRedisSerializer jsonRedisSerializer = 
            							new GenericJackson2JsonRedisSerializer();
        // 设置Key的序列化
        template.setKeySerializer(RedisSerializer.string());
        template.setHashKeySerializer(RedisSerializer.string());
        // 设置Value的序列化
        template.setValueSerializer(jsonRedisSerializer);
        template.setHashValueSerializer(jsonRedisSerializer);
        // 返回
        return template;
    }
}

```

这里采用了JSON序列化来代替默认的JDK序列化方式

#### <font style="color:#DF2A3F;">StringRedisTemplate序列化</font>方式:
统一使用String序列化器，要求只能存储String类型的key和value。当需要存储Java对象时，手动完成对象的序列化和反序列化

这种用法比较普遍，因此SpringDataRedis就提供了RedisTemplate的子类：StringRedisTemplate，它的key和value的序列化方式默认就是String方式。

省去了我们自定义RedisTemplate的序列化方式的步骤，而是直接使用：

```python
@Autowired
private StringRedisTemplate stringRedisTemplate;
// JSON序列化工具
private static final ObjectMapper mapper = new ObjectMapper();

@Test
void testSaveUser() throws JsonProcessingException {
    // 创建对象
    User user = new User("虎哥", 21);
    // 手动序列化
    String json = mapper.writeValueAsString(user);
    // 写入数据
    stringRedisTemplate.opsForValue().set("user:200", json);

    // 获取数据
    String jsonUser = stringRedisTemplate.opsForValue().get("user:200");
    // 手动反序列化
    User user1 = mapper.readValue(jsonUser, User.class);
    System.out.println("user1 = " + user1);
}


```

### Redis使用相关
- redis-cli：是redis提供的命令行客户端

- redis-server：是redis的服务端启动脚本

- redis-sentinel：是redis的哨兵启动脚本

配置相关的信息在conf文件操作

启动redis指令： `redis-server redis.conf`

Redis的java客户端





## mybatis-plus 使用
```plain
// 4.一致，根据手机号查询用户 select * from tb_user where phone = ?
User user = query().eq("phone", phone).one();
```

## Token 生成
```plain
// 7.1.随机生成token，作为登录令牌
String token = UUID.randomUUID().toString( true);
```



[https://blog.csdn.net/nawenqiang/article/details/82684001](https://blog.csdn.net/nawenqiang/article/details/82684001)

## 
## 功能实现
### 基于Session实现短信验证码登录
:::success
要点:

理解tomcat中session概念

理解tomcat线程的概念

理解threadlocal概念

:::

![](/images/9231dab9ead02c97353beebfdf0df5f2.png)

发送验证码:

校验手机号----调用RegexUtil工具类判断

生成校验码  ----调用工具类<font style="color:#262626;background-color:#f2f3f7;">RandomUtil.</font>生成随机码

保存验证码到session ---这里直接是存放在传进来的参数HttpSession session中

短信验证码登录:

校验验证码----直接session提取然后和表单验证码对比

查询用户----mybatisplus查询

创建用户---mybatisplus创建

校验登录状态:

![](/images/d52ed8204bd5454e0513be46e573a964.png)

使用LoginInterceptor拦截器统一实现校验状态

前置拦截-----

从session获取user字段

判断user字段是否为null

保存user字段到ThreadLocal中

![](/images/ccca9df73d51420aad14111e7dffff54.png)

放行----user controller里面 me方法

配置MvcConfig

添加拦截器add interceptor

#### session实现登录验证存在的问题: 
多台tomcat不共享session存储空间,切换tomcat服务室会出现数据丢失问题.

 不便于之后扩展增减tomcat服务器做负载均衡

![](/images/4503190fcefe7a39a318c4f17e0f91d1.png)

### 基于redis实现共享session登录
![](/images/45ec52ad0f2cf5f122565e7818de5775.png)

![](/images/ce4596282543e408336507d7a9cb289b.png)

发送验证码sendCode:

校验手机号----调用RegexUtil工具类判断

生成校验码  ----调用工具类<font style="color:#262626;background-color:#f2f3f7;">RandomUtil.</font>生成随机码

保存验证码到redis ---使用hash结构向redis添加验证码,注意key前缀



短信验证码登录 login:

    1. 校验验证码----直接session提取然后和表单验证码对比
    2. 查询用户----mybatisplus查询
    3. 随机生成token ---UUID
    4. 批量将user字段存储在redis中
        * 将user对象转化成HashMap
        * 调用putAll**<font style="color:#DF2A3F;">批量导入</font>**kv

![](/images/c10841fbdb72a91f8dab25de9ee57d81.png)

这里StringRedisTemplete所有kv要求是string,Bean.beanToMap还能有自定义参数,将所有字段的值都转化成string![](/images/a646b864155a31e00e1d77cf75a45e58.png)

        * 有效期设置问题----token有效期因该是未操作固定时间后失效
    5. 返回token给前端,token会作为请求头里面authorize参数携带
    6. 更新token有效期----配置拦截器RefreshTokenInterceptor

RefreshTokenInterceptor主要工作是查询是否有用户并保存到threadlocal中并刷新有效期

拦截器会首先提取请求头携带的token然后查询是否存在该用户。

拦截器默认拦截所有的站点。

这里需要考虑拦截器初始化时机,注入redisTemplate使用构造函数手动注入 ,因为拦截器类没有被添加注解让spring来初始化



需要取到的是哈希里面的所有字段键值对,使用entries方法

![](/images/da867a2de243772a3615ff0d5634c31e.png)

再把HasMap转为UserDTO

![](/images/143ecc04877146ec616267dd750e515d.png)

保存用户到Threadlocal

刷新token有效期

![](/images/b2dba539bc3f9c6ea6d80eccff5e278a.png)



校验登录状态:

使用LoginInterceptor拦截器统一实现拦截和校验登录,拦截器在MvConfig中优先级为1低于RefreshTokenInterceptor拦截器

此时只需要从Threadlocal中直接获取user即可

放行----user controller里面 me方法

配置MvcConfig

添加拦截器add interceptor

重点:拦截器的优化

### 过滤器、拦截器执行顺序


[https://blog.csdn.net/weixin_45855671/article/details/116041388](https://blog.csdn.net/weixin_45855671/article/details/116041388)

### 
### 缓存更新策略
缓存的使用: 降低了后端负载，提高了读写的效率，降低了响应的时间 ,代价提高了系统的维护成本，同时也带来了数据一致性问题



<font style="background-color:rgba(255, 255, 255, 0);">**内存淘汰：redis自动进行，当redis内存达到咱们设定的max-memery的时候，会自动触发淘汰机制，淘汰掉一些不重要的数据(可以自己设置策略方式)</font>

<font style="background-color:rgba(255, 255, 255, 0);">**超时剔除：当我们给redis设置了过期时间ttl之后，redis会将超时的数据进行删除，方便咱们继续使用缓存</font>

<font style="background-color:rgba(255, 255, 255, 0);">**主动更新：我们可以手动调用方法把缓存删掉，通常用于解决缓存和数据库不一致问题</font>

![](/images/1f7bfd26473e1f2e0fc274a4b1d5fc99.png)

#### <font style="color:#262626;">数据库与缓存不一致解决方案</font>
解决方案:

<font style="color:rgb(197, 200, 198);background-color:rgb(29, 31, 33);">Cache Aside Pattern 人工编码方式：缓存调用者在更新完数据库后再去更新缓存，也称之为双写方案</font>

<font style="color:rgb(197, 200, 198);background-color:rgb(29, 31, 33);">Read/Write Through Pattern : 由系统本身完成，数据库与缓存的问题交由系统本身去处理</font>

<font style="color:rgb(197, 200, 198);background-color:rgb(29, 31, 33);">Write Behind Caching Pattern ：调用者只操作缓存，其他线程去异步处理数据库，实现最终一致</font>

![](/images/a1388b47fe68e163e0e8bfb639f8b45b.png)

#### 人工编码方式
有三个问题需要考虑:

1. 数据库更新之后,删除缓存还是更新缓存？
+ 更新缓存：每次更新数据库都更新缓存，无效写操作较多
+ 删除缓存：更新数据库时让缓存失效，查询时再更新缓存
2. 如何保证缓存与数据库的操作的同时成功或失败？
    - 单体系统，将缓存与数据库操作放在一个事务
    - 分布式系统，利用TCC等分布式事务方案
3. 先操作缓存还是先操作数据库？
    - 先删除缓存，再操作数据库
    - 先操作数据库，再删除缓存



人工编码方式缓存更新策略三种:

##### 双写策略:
+ <font style="color:rgb(245, 240, 232);background-color:rgb(29, 31, 32);">查询：先查询缓存，如果缓存中没有，则查询数据库，并将结果写入缓存</font>
+ <font style="color:rgb(245, 240, 232);background-color:rgb(29, 31, 32);">更新：先更新数据库，然后删除缓存或者更新缓存</font>

~~更新缓存模式~~：每次更新数据库都更新缓存，无效写操作较多（不推荐使用）

> 假如我们执行上百次更新数据库操作，那么就要执行上百次写入缓存的操作，而在这期间并没有查询请求，那么这上百次写入缓存的操作就显得没有什么意义
>

 删除缓存模式：更新数据时更新数据库并删除缓存，查询时更新缓存，无效写操作较少（推荐使用）

> 当线程1在查询缓存且未命中，此时线程1查询数据，查询完准备写入缓存时，由于没有加锁线程2乘虚而入，线程2在这期间对数据库进行了更新，此时线程1将旧数据返回了，出现了脏读，这个事件发生的概率很低，因为先是需要满足缓存未命中，且在写入缓存的那段事件内有一个线程进行更新操作，缓存的查询很快，这段空隙时间很小，所以出现脏读现象的概率也很低
>
> 这种方式的不足之处：存在脏读现象，但概率较小
>

![](/images/d8ea62cabe9338702622962b5cbf35e4.png)



##### 读写穿透方案（Read/Write Through Pattern）
将读取和写入操作首先在缓存中执行，然后再传播到数据存储

1）读取穿透（Read Through）：当进行读取请求时，首先检查缓存。如果所请求的数据在缓存中找到，直接返回数据。如果缓存中没有找到数据，则将请求转发给数据存储以获取数据。获取到的数据随后存储在缓存中，然后返回给调用者。

2）写入穿透（Write Through）：当进行写入请求时，首先将数据写入缓存。缓存立即将写操作传播到数据存储，确保缓存和数据存储之间的数据保持一致。这样保证了后续的读取请求从缓存中返回更新后的数据。

##### 写回方案（Write Behind Caching Pattern）
调用者只操作缓存，其他线程去异步处理数据库，实现最终一致

1）读取（Read）：先检查缓存中是否存在数据，如果不存在，则从底层数据存储中获取数据，并将数据存储到缓存中。

2）写入（Write）：先更新底层数据存储，然后将待写入的数据放入一个缓存队列中。在适当的时机，通过批量操作或异步处理，将缓存队列中的数据写入底层数据存储



##### 主动更新策略中三种方案的比较：
双写方案 和 读写穿透方案 在写入数据时都会直接更新缓存，以保持缓存和底层数据存储的一致性。而 写回方案 延迟了缓存的更新操作，将数据先放入缓存队列，然后再进行批量或异步写入。

读写穿透方案 和 写回方案 相比，写回方案 具有更高的写入性能，因为它通过批量和异步操作减少了频繁的写入操作。但是 写回方案 带来了数据一致性的考虑，需要确保缓存和底层数据存储在某个时间点上保持一致，而 读写穿透方案 将数据库和缓存整合为一个服务，由服务来维护缓存与数据库的一致性，调用者无需关心数据一致性问题，降低了系统的可维护性，但是实现困难

主动更新策略中三种方案的应用场景：

双写方案 较适用于读多写少的场景，数据的一致性由应用程序主动管理

读写穿透方案 适用于数据实时性要求较高、对一致性要求严格的场景

写回方案 适用于追求写入性能的场景，对数据的实时性要求相对较低、可靠性也相对低



### 商铺缓存与数据库双写一致
> 缓存主动更新策略  选择使用双写方案的删除缓存模式   减少线程安全问题的发生的概率,采用 TTL过期+内存淘汰机制 兜底 ,
>

![](/images/e7d0366b055803d2400181b61e74844a.png)

**ShopServiceImpl**的queryById方法

![](/images/b62b1ec38ae199f0c3e60f5291181372.png)

     		增加 设置缓存时添加过期时间

**ShopServiceImpl**的update方法:

更新数据库 

删除redis缓存

#### 缓存穿透  商铺查询的缓存穿透
> 缓存穿透是指客户端请求的数据在缓存中和数据库中都不存在，这样缓存永远不会生效，这些请求都会打到数据库
>

![](/images/29a3d77d313f1896b9c559d7b44d9d24.png)

常见解决缓存穿透的解决方案：

+ 缓存空对象
    - 优点：实现简单，维护方便
    - 缺点：额外的内存消耗，可能造成短期的不一致
+ 布隆过滤
    - 优点：内存占用较少，没有多余key
    - 缺点：实现复杂，存在误判可能（有穿透的风险），无法删除数据
+ 主动方案预防缓存穿透:
+ 增强id的复杂度避免被猜测id规律、做好数据的基础格式校验、加强用户权限校验、做好热点参数的限流![](/images/32f8678d18d5de68c1f25c22f1b149f2.png)

解决商铺查询的缓存穿透问题:

+ ![](/images/43482e29113a7e25a9100cfc6fae8aad.png)

#### 缓存雪崩
> 缓存雪崩是指在同一时段大量的缓存key同时失效或者Redis服务宕机，导致大量请求到达数据库，带来巨大压力。
>

![](/images/5dc7d85be9cc69b05f39c713f500771f.png)

缓存雪崩的常见解决方案：

+ <font style="color:#DF2A3F;">给不同的Key的TTL添加随机值</font>
+ <font style="color:#DF2A3F;">利用Redis集群提高服务的可用性</font>
+ <font style="color:#DF2A3F;">给缓存业务添加降级限流策略</font>，比如快速失败机制，让请求尽可能打不到数据库上
+ <font style="color:#DF2A3F;">给业务添加多级缓存</font>

#### 缓存击穿的解决方案
> 缓存击穿问题也叫热点Key问题，就是一个被高并发访问并且缓存重建业务较复杂的key突然失效了，无数的请求访问会在瞬间给数据库带来巨大的冲击。
>

![](/images/7449af0863168dbae9be0960052997a9.png)

缓存击穿的常见解决方案：

+ 互斥锁（时间换空间）
    - 优点：内存占用小，一致性高，实现简单
    - 缺点：性能较低，容易出现死锁
+ 逻辑过期（空间换时间）
    - 优点：性能高
    - 缺点：内存占用较大，容易出现脏读

互斥锁更加易于实现，但是容易发生死锁，且锁导致并行变成串行，导致系统性能下降

逻辑过期实现起来相较复杂，且需要耗费额外的内存，但是通过开启子线程重建缓存，使原来的同步阻塞变成异步，提高系统的响应速度，但是容易出现脏读

![](/images/28a817f468757aa75df70ee15c30f7e8.png)

##### 互斥锁实现根据id查询商铺
这里使用Redis中的`setnx`指令实现互斥锁，只有当值不存在时才能进行`set`操作

![](/images/ed93d19bb3e3d20134f33a77b6dfc0dd.png)

备注：

1. 这里使用Redis中的`<font style="color:rgb(255, 88, 132);background-color:rgb(50, 24, 31);">setnx</font>`指令实现互斥锁，只有当值不存在时才能进行`<font style="color:rgb(255, 88, 132);background-color:rgb(50, 24, 31);">set</font>`操作
2. 锁的有效期更具体业务有关，需要灵活变动，一般锁的有效期是业务处理时长10~20倍
3. 使用递归实现获取锁失败后循环尝试
4. 线程获取锁后，还需要查询缓存（也就是所谓的双检），这样才能够真正有效保障缓存不被击穿

```java
/**
     * 根据id查询商铺数据
     *
     * @param id
     * @return
     */
@Override
public Result queryById(Long id) {
String key = CACHE_SHOP_KEY + id;
// 1、从Redis中查询店铺数据，并判断缓存是否命中
Result result = getShopFromCache(key);
if (Objects.nonNull(result)) {
    // 缓存命中，直接返回
    return result;
}
try {
    // 2、缓存未命中，需要重建缓存，判断能否能够获取互斥锁
    String lockKey = LOCK_SHOP_KEY + id;
    boolean isLock = tryLock(lockKey);
    if (!isLock) {
        // 2.1 获取锁失败，已有线程在重建缓存，则休眠重试
        Thread.sleep(50);
        return queryById(id);
    }
    // 2.2 获取锁成功，判断缓存是否重建，防止堆积的线程全部请求数据库（所以说双检是很有必要的）
    result = getShopFromCache(key);
    if (Objects.nonNull(result)) {
        // 缓存命中，直接返回
        return result;
    }

    // 3、从数据库中查询店铺数据，并判断数据库是否存在店铺数据
    Shop shop = this.getById(id);
    if (Objects.isNull(shop)) {
        // 数据库中不存在，缓存空对象（解决缓存穿透），返回失败信息
        stringRedisTemplate.opsForValue().set(key, "", CACHE_NULL_TTL, TimeUnit.SECONDS);
        return Result.fail("店铺不存在");
    }

    // 4、数据库中存在，重建缓存，响应数据
    stringRedisTemplate.opsForValue().set(key, JSONUtil.toJsonStr(shop),
                                          CACHE_SHOP_TTL, TimeUnit.MINUTES);
    return Result.ok(shop);
}catch (Exception e){
    throw new RuntimeException("发生异常");
} finally {
    // 5、释放锁（释放锁一定要记得放在finally中，防止死锁）
    unlock(key);
}
}

/**
     * 从缓存中获取店铺数据
     * @param key
     * @return
     */
private Result getShopFromCache(String key) {
    String shopJson = stringRedisTemplate.opsForValue().get(key);
    // 判断缓存是否命中
    if (StrUtil.isNotBlank(shopJson)) {
        // 缓存数据有值，说明缓存命中了，直接返回店铺数据
        Shop shop = JSONUtil.toBean(shopJson, Shop.class);
        return Result.ok(shop);
    }
    // 判断缓存中查询的数据是否是空字符串(isNotBlank把 null 和 空字符串 给排除了)
    if (Objects.nonNull(shopJson)) {
        // 当前数据是空字符串，说明缓存也命中了（该数据是之前缓存的空对象），直接返回失败信息
        return Result.fail("店铺不存在");
    }
    // 缓存未命中（缓存数据既没有值，又不是空字符串）
    return null;
}


/**
     * 获取锁
     *
     * @param key
     * @return
     */
private boolean tryLock(String key) {
Boolean flag = stringRedisTemplate.opsForValue().setIfAbsent(key, "1", 10, TimeUnit.SECONDS);
// 拆箱要判空，防止NPE
return BooleanUtil.isTrue(flag);
}

/**
     * 释放锁
     *
     * @param key
     */
private void unlock(String key) {
    stringRedisTemplate.delete(key);
}

```

##### 基于逻辑过期解决缓存穿透  
> 新增一个字段，用来标记key的过期时间，这样能能够避免key过期而被自动删除，这样数据就永不过期了，从根本上解决因为热点key过期导致的缓存击穿。一般搞活动时，比如抢优惠券，秒杀等场景，请求量比较大就可以使用逻辑过期，等活动一过就手动删除逻辑过期的数据
>

![](/images/a17ceef102b03414100626218376672d.png)

这里主要关注的重点有:

1. 对于我们的shop数据,如何增加一个逻辑过期时间

如果我们直接修改shop实体类增加一个逻辑过期字段,那么修改了原本的业务逻辑代码

如果新建一个数据类,里面添加一个逻辑过期属性,让shop继承这个类从而获得该属性,修改的源代码较少,但还是有

如果新建一个实体类,设立一个object类型存储shop数据可以解决问题

2. object类型的数据在存储进redis的时候取出后的格式转换问题

由于使用的JsonUtil转化为json字符串,在从redis取出之后的对象需要先反序列化,默认转为JsonObject类型,无法直接用Shop类型接受,需要先使用JsonUtil进行类型转换

3. 开启新线程进行缓存重建

最好使用一个线程池开启线程,性能较好

4. 线程重建缓存的时候注意释放锁使用try finally强制释放
5. 双检:获取锁成功之后,应该再次检测redis缓存是否过期,避免并发线程在

<font style="color:rgb(255, 255, 255);background-color:rgb(148, 148, 6);">注意</font>：逻辑过期一定要先进行数据预热，将我们热点数据加载到缓存中

总结:

1. <font style="color:rgba(255, 255, 255, 0.75);background-color:rgb(29, 31, 32);">逻辑过期时间根据具体业务而定，逻辑过期过长，会造成缓存数据的堆积，浪费内存，过短造成频繁缓存重建，降低性能，所以设置逻辑过期时间时需要实际测试和评估不同参数下的性能和资源消耗情况，可以通过观察系统的表现，在业务需求和性能要求之间找到一个平衡点</font>

```python
    /**
     * 缓存重建线程池
     */
    public static final ExecutorService CACHE_REBUILD_EXECUTOR = Executors.newFixedThreadPool(10);

    /**
     * 根据id查询商铺数据
     *
     * @param id
     * @return
     */
    @Override
    public Result queryById(Long id) {
        String key = CACHE_SHOP_KEY + id;
        // 1、从Redis中查询店铺数据，并判断缓存是否命中
        String shopJson = stringRedisTemplate.opsForValue().get(key);
        if (StrUtil.isBlank(shopJson)) {
            // 1.1 缓存未命中，直接返回失败信息
            return Result.fail("店铺数据不存在");
        }
        // 1.2 缓存命中，将JSON字符串反序列化未对象，并判断缓存数据是否逻辑过期
        RedisData redisData = JSONUtil.toBean(shopJson, RedisData.class);
        // 这里需要先转成JSONObject再转成反序列化，否则可能无法正确映射Shop的字段
        JSONObject data = (JSONObject) redisData.getData();
        Shop shop = JSONUtil.toBean(data, Shop.class);
        LocalDateTime expireTime = redisData.getExpireTime();
        if (expireTime.isAfter(LocalDateTime.now())) {
            // 当前缓存数据未过期，直接返回
            return Result.ok(shop);
        }

        // 2、缓存数据已过期，获取互斥锁，并且重建缓存
        String lockKey = LOCK_SHOP_KEY + id;
        boolean isLock = tryLock(lockKey);
        if (isLock) {
            // 获取锁成功，开启一个子线程去重建缓存
            CACHE_REBUILD_EXECUTOR.submit(() -> {
                try {
                    this.saveShopToCache(id, CACHE_SHOP_LOGICAL_TTL);
                } finally {
                    unlock(lockKey);
                }
            });
        }

        // 3、获取锁失败，再次查询缓存，判断缓存是否重建（这里双检是有必要的）
        shopJson = stringRedisTemplate.opsForValue().get(key);
        if (StrUtil.isBlank(shopJson)) {
            // 3.1 缓存未命中，直接返回失败信息
            return Result.fail("店铺数据不存在");
        }
        // 3.2 缓存命中，将JSON字符串反序列化未对象，并判断缓存数据是否逻辑过期
        redisData = JSONUtil.toBean(shopJson, RedisData.class);
        // 这里需要先转成JSONObject再转成反序列化，否则可能无法正确映射Shop的字段
        data = (JSONObject) redisData.getData();
        shop = JSONUtil.toBean(data, Shop.class);
        expireTime = redisData.getExpireTime();
        if (expireTime.isAfter(LocalDateTime.now())) {
            // 当前缓存数据未过期，直接返回
            return Result.ok(shop);
        }

        // 4、返回过期数据
        return Result.ok(shop);
    }

    /**
     * 将数据保存到缓存中
     *
     * @param id            商铺id
     * @param expireSeconds 逻辑过期时间
     */
    public void saveShopToCache(Long id, Long expireSeconds) {
        // 从数据库中查询店铺数据
        Shop shop = this.getById(id);
        // 封装逻辑过期数据
        RedisData redisData = new RedisData();
        redisData.setData(shop);
        redisData.setExpireTime(LocalDateTime.now().plusSeconds(expireSeconds));
        // 将逻辑过期数据存入Redis中
        stringRedisTemplate.opsForValue().set(CACHE_SHOP_KEY + id, JSONUtil.toJsonStr(redisData));
    }

    /**
     * 获取锁
     *
     * @param key
     * @return
     */
    private boolean tryLock(String key) {
        Boolean flag = stringRedisTemplate.opsForValue().setIfAbsent(key, "1", 10, TimeUnit.SECONDS);
        // 拆箱要判空，防止NPE
        return BooleanUtil.isTrue(flag);
    }

    /**
     * 释放锁
     *
     * @param key
     */
    private void unlock(String key) {
        stringRedisTemplate.delete(key);
    }

```

#### 总结
为了解决数据一致性问题，我们可以选择适当的缓存更新策略：

以缓存主动更新（双写方案+删除缓存模式+先操作数据库后操作缓存+事务）为主，超时剔除为辅

查询时，先查询缓存，缓存命中直接返回，缓存未命中查询数据库并重建缓存，返回查询结果

更新时，先修改数据删除缓存，使用事务保证缓存和数据操作两者的原子性

除了会遇到数据一致性问题意外，我们还会遇到缓存穿透、缓存雪崩、缓存击穿等问题

对于缓存穿透，我们采用了**缓存空对象**解决

对于缓存击穿，我们分别演示了互斥锁（setnx实现方式）和逻辑过期两种方式解决

### 优惠券秒杀
**<font style="color:#DF2A3F;">自增ID存在的问题</font>**

当用户抢购时，就会生成订单并保存到tb_voucher_order这张表中，而订单表如果使用数据库自增ID就存在一些问题：

1. id的规律性太明显，容易出现信息的泄露，被不怀好意的人伪造请求
2. 受单表数据量的限制，MySQL中表能够存储的数据有限，会出现分库分表的情况，id不能够一直自增

当ID规律过于明显时，存在以下一些缺点：

1. 安全性问题：如果ID规律太明显，可能会使系统容易受到恶意攻击，例如暴力破解等。
2. 隐私泄露风险：如果ID规律太明显，可能导致用户的个人信息或敏感数据被曝光。
3. 数据可预测性：当ID规律太明显时，使用这些规律的攻击者可以很轻易地猜测出其他实体（如订单、交易等）的ID。
4. 扩展性受限：如果ID规律太明显，可能会对系统的扩展性造成一定影响。
5. 维护困难：当ID规律太明显时，系统可能需要额外的资源和机制来保持规律的更新和变化

解决:使用<font style="background-color:#F1A2AB;">分布式ID</font>（也可以叫全局唯一ID）

#### 分布式ID的实现
分布式ID的实现方式：

1. UUID
2. Redis自增
3. 数据库自增
4. snowflake算法（雪花算法）

这里我们使用自定义的方式实现：<font style="background-color:#F1A2AB;">时间戳+序列号+数据库自增</font>

为了增加ID的安全性，我们可以不直接使用Redis自增的数值，而是拼接一些其它信息，比如时间戳、UUID、业务关键词

![](/images/bf66c4950f0760c7269404943ca4bd9e.png)

符号位：1bit，永远为0（表示正数）

时间戳：31bit，以秒为单位，可以使用69年

序列号：32bit，秒内的计数器，支持每秒产生2^32个不同ID

```python
@Component
public class RedisIdWorker {
    /**
     * 开始时间戳
     */
    private static final long BEGIN_TIMESTAMP = 1640995200L;
    /**
     * 序列号的位数
     */
    private static final int COUNT_BITS = 32;

    private StringRedisTemplate stringRedisTemplate;

    public RedisIdWorker(StringRedisTemplate stringRedisTemplate) {
        this.stringRedisTemplate = stringRedisTemplate;
    }

    public long nextId(String keyPrefix) {
        // 1.生成时间戳
        LocalDateTime now = LocalDateTime.now();
        long nowSecond = now.toEpochSecond(ZoneOffset.UTC);
        long timestamp = nowSecond - BEGIN_TIMESTAMP;

        // 2.生成序列号
        // 2.1.获取当前日期，精确到天
        String date = now.format(DateTimeFormatter.ofPattern("yyyy:MM:dd"));
        // 2.2.自增长
        long count = stringRedisTemplate.opsForValue().increment("icr:" + keyPrefix + ":" + date);

        // 3.拼接并返回
        return timestamp << COUNT_BITS | count;
    }
}

```

优惠券秒杀下单

![](/images/2572fd63c521a12b377376940fef24aa.png)

普通分布式ID+事务 实现 优惠券秒杀

```java
/**
     * 抢购秒杀券
     *
     * @param voucherId
     * @return
     */
@Transactional
@Override
public Result seckillVoucher(Long voucherId) {
    // 1、查询秒杀券
    SeckillVoucher voucher = seckillVoucherService.getById(voucherId);
    // 2、判断秒杀券是否合法
    if (voucher.getBeginTime().isAfter(LocalDateTime.now())) {
        // 秒杀券的开始时间在当前时间之后
        return Result.fail("秒杀尚未开始");
    }
    if (voucher.getEndTime().isBefore(LocalDateTime.now())) {
        // 秒杀券的结束时间在当前时间之前
        return Result.fail("秒杀已结束");
    }
    if (voucher.getStock() < 1) {
        return Result.fail("秒杀券已抢空");
    }
    // 5、秒杀券合法，则秒杀券抢购成功，秒杀券库存数量减一
    boolean flag = seckillVoucherService.update(new LambdaUpdateWrapper<SeckillVoucher>()
                                                .eq(SeckillVoucher::getVoucherId, voucherId)
                                                .setSql("stock = stock -1"));
    if (!flag){
        throw new RuntimeException("秒杀券扣减失败");
    }
    // 6、秒杀成功，创建对应的订单，并保存到数据库
    VoucherOrder voucherOrder = new VoucherOrder();
    long orderId = redisIdWorker.nextId(SECKILL_VOUCHER_ORDER);
    voucherOrder.setId(orderId);
    voucherOrder.setUserId(ThreadLocalUtls.getUser().getId());
    voucherOrder.setVoucherId(voucherOrder.getId());
    flag = this.save(voucherOrder);
    if (!flag){
        throw new RuntimeException("创建秒杀券订单失败");
    }
    // 返回订单id
    return Result.ok(orderId);
}

```

存在<font style="background-color:#FBDE28;">超卖问题</font>:     多个线程同时都检查到还有库存导致后续超卖

**<font style="color:rgb(221, 212, 202);background-color:rgb(29, 31, 32);">超卖问题的常见解决方案</font>**<font style="color:rgb(221, 212, 202);background-color:rgb(29, 31, 32);">：</font>

1. 悲观锁，认为线程安全问题一定会发生，因此操作数据库之前都需要先获取锁，确保线程串行执行。常见的悲观锁有：synchronized、lock
2. 乐观锁，认为线程安全问题不一定发生，因此不加锁，只会在更新数据库的时候去判断有没有其它线程对数据进行修改，如果没有修改则认为是安全的，直接更新数据库中的数据即可，如果修改了则说明不安全，直接抛异常或者等待重试。常见的实现方式有：<font style="color:#000000;background-color:#FBE4E7;">版本号法、CAS操作、乐观锁算法</font>



#### <font style="color:rgb(218, 211, 199);background-color:rgb(29, 31, 32);">一人多单情况下 乐观锁解决超卖问题</font>
<font style="color:rgb(221, 212, 202);background-color:rgb(29, 31, 32);">版本号法</font>

![](/images/cd598ec23fe11c7dc400430231c58685.png)

CAS法: compare and swap 

![](/images/e1491881f5909c22ea458caaf05e9a3d.png)

弊端:并发的时候,会出现许多并发线程在判断时已经被修改导致都失败

改进: 只判断库存大于0   这里实际还是将判断交给了数据库,数据库的行锁限制了每次只有一个线程完成修改

#### 一人一单情况下   悲观锁解决超卖问题
> 乐观锁需要判断数据是否修改，而当前是判断当前是否存在，所以无法像解决库存超卖一样使用CAS机制，但是可以使用版本号法，但是版本号法需要新增一个字段，所以这里为了方便，就直接演示使用悲观锁解决超卖问题
>

![](/images/8eb0cdd94c9e93bf197621247d49767d.png)

```java
    /**
     * 抢购秒杀券
     *
     * @param voucherId
     * @return
     */
    @Transactional
    @Override
    public Result seckillVoucher(Long voucherId) {
        // 1、查询秒杀券
        SeckillVoucher voucher = seckillVoucherService.getById(voucherId);
        // 2、判断秒杀券是否合法
        if (voucher.getBeginTime().isAfter(LocalDateTime.now())) {
            // 秒杀券的开始时间在当前时间之后
            return Result.fail("秒杀尚未开始");
        }
        if (voucher.getEndTime().isBefore(LocalDateTime.now())) {
            // 秒杀券的结束时间在当前时间之前
            return Result.fail("秒杀已结束");
        }
        if (voucher.getStock() < 1) {
            return Result.fail("秒杀券已抢空");
        }
        // 3、创建订单
        Long userId = ThreadLocalUtls.getUser().getId();
        synchronized (userId.toString().intern()) {
            // 创建代理对象，使用代理对象调用第三方事务方法， 防止事务失效
            IVoucherOrderService proxy = (IVoucherOrderService) AopContext.currentProxy();
            return proxy.createVoucherOrder(userId, voucherId);
        }
    }

    /**
     * 创建订单
     *
     * @param userId
     * @param voucherId
     * @return
     */
    @Transactional
    public Result createVoucherOrder(Long userId, Long voucherId) {
//        synchronized (userId.toString().intern()) {
        // 1、判断当前用户是否是第一单
        int count = this.count(new LambdaQueryWrapper<VoucherOrder>()
                .eq(VoucherOrder::getUserId, userId));
        if (count >= 1) {
            // 当前用户不是第一单
            return Result.fail("用户已购买");
        }
        // 2、用户是第一单，可以下单，秒杀券库存数量减一
        boolean flag = seckillVoucherService.update(new LambdaUpdateWrapper<SeckillVoucher>()
                .eq(SeckillVoucher::getVoucherId, voucherId)
                .gt(SeckillVoucher::getStock, 0)
                .setSql("stock = stock -1"));
        if (!flag) {
            throw new RuntimeException("秒杀券扣减失败");
        }
        // 3、创建对应的订单，并保存到数据库
        VoucherOrder voucherOrder = new VoucherOrder();
        long orderId = redisIdWorker.nextId(SECKILL_VOUCHER_ORDER);
        voucherOrder.setId(orderId);
        voucherOrder.setUserId(ThreadLocalUtls.getUser().getId());
        voucherOrder.setVoucherId(voucherOrder.getId());
        flag = this.save(voucherOrder);
        if (!flag) {
            throw new RuntimeException("创建秒杀券订单失败");
        }
        // 4、返回订单id
        return Result.ok(orderId);
//        }
    }

```

实现细节：

    1. 锁的范围尽量小。synchronized尽量锁代码块，而不是方法，锁的范围越大性能越低
    2. 锁的对象一定要是一个不变的值。我们不能直接锁 Long 类型的 userId，每请求一次都会创建一个新的 userId 对象，synchronized 要锁不变的值，所以我们要将 Long 类型的 userId 通过 toString()方法转成 String 类型的 userId，toString()方法底层（可以点击去看源码）是直接 new 一个新的String对象，显然还是在变，所以我们要使用 intern() 方法从常量池中寻找与当前 字符串值一致的字符串对象，这就能够保障一个用户 发送多次请求，每次请求的 userId 都是不变的，从而能够完成锁的效果（并行变串行）
    3. 我们要锁住整个事务，而不是锁住事务内部的代码。如果我们锁住事务内部的代码会导致其它线程能够进入事务，当我们事务还未提交，锁一旦释放，仍然会存在超卖问题
    4. Spring的@Transactional注解要想事务生效，必须使用动态代理。Service中一个方法中调用另一个方法，另一个方法使用了事务，此时会导致@Transactional失效，所以我们需要创建一个代理对象，使用代理对象来调用方法。

补充知识:

1. 复习  Tomcat 与 Spring 协作处理并发请求的核心过程

![](/images/c79a6a8c5af5d85a2ced01d2978fbad6.png)

2. synchronized锁的范围与粒度
+ 方法体上加 `**<font style="background-color:rgba(255, 255, 255, 0);">synchronized</font>**`：这是粗粒度锁。它将整个方法体作为同步代码块。只要有一个线程进入了该同步方法，其他所有线程都无法访问该实例的任何 `**<font style="background-color:rgba(255, 255, 255, 0);">synchronized</font>**`方法（对于静态同步方法，则是该类的所有 `**<font style="background-color:rgba(255, 255, 255, 0);">synchronized static</font>**`方法）。
+ 方法体内部加 `**<font style="background-color:rgba(255, 255, 255, 0);">synchronized</font>**`：这是细粒度锁。它允许你只将真正需要同步的核心临界区代码（例如检查并创建订单）用 `**<font style="background-color:rgba(255, 255, 255, 0);">synchronized</font>**`块包裹起来。方法内的其他操作（如参数校验、查询库存等）可以被多个线程并发执行，从而提高了性能
3. synchronized锁的对象
    - 方法体上加 `**<font style="background-color:rgba(255, 255, 255, 0);">synchronized</font>**`：
        * •对于实例方法，锁对象是当前实例（`**<font style="background-color:rgba(255, 255, 255, 0);">this</font>**`）。
        * •对于静态方法，锁对象是当前类的 `**<font style="background-color:rgba(255, 255, 255, 0);">Class</font>**`对象。
    - 方法体内部加 `**<font style="background-color:rgba(255, 255, 255, 0);">synchronized</font>**`：你可以灵活指定锁对象。在“一人一单”场景中，通常需要以用户ID为维度进行加锁，以确保同一用户的操作串行化
4. 使用userId.toString()对于灭

```java
synchronized(userId.toString().intern()) { // 使用intern()确保字符串常量池中的唯一性
    // 检查并创建订单
}
```

5. synchronized锁与Spring事务的交互  
这是一个非常关键的区别点！

• 方法体上加 synchronized：可能会引发并发安全问题。因为 synchronized锁的释放是在方法执行结束时，而 Spring 的 @Transactional事务提交是在方法返回之后。这意味着，一个线程可能已经执行完同步方法并释放了锁，但事务还未提交。此时另一个线程可以获得锁并进入方法，它查询数据库时可能还看不到前一个线程未提交的订单数据，从而导致“一人一单”的检查失效，最终创建多个订单  
。 方法体内部加 synchronized：如果将 synchronized块写在事务方法内部，并且在调用代理对象的事务方法之前加锁，那么锁的生命周期就覆盖了整个事务过程。这样可以确保在事务提交后才会释放锁，从而避免了上述问题  
。 通常需要结合 AopContext.currentProxy()来获取当前类的代理对象以调用内部事务方法。

| 特性 | 代理对象 (Proxy Object) | this 对象 (真实对象) |
| :---: | :---: | :---: |
| 来源 | 由 Spring 框架通过 CGLIB 或 JDK 动态代理 技术生成 | 就是你编写的那个类的 普通实例 |
| 关系 | 包装了真实对象，是真实对象的“替身” | 被代理对象所包装的 内部核心 |
| 职责 | 拦截方法调用，在目标方法执行前后加入增强逻辑（如开启事务、安全校验等） | 纯粹执行业务逻辑 |
| 事务生效 | ✅ 只有通过代理对象调用，`@Transactional`等注解才生效 | ❌ 直接通过 `this`调用，事务等 AOP 增强全部失效 |


事务注解如果想要生效,实际上是Spring对事务注解所在的类做了动态代理,拿到类的代理对象,然后做的事务处理

这里的关键问题在于：锁（Synchronized）的边界与事务的边界不一致：`synchronized`代码块结束时，锁就释放了。但 Spring 的事务是在代理方法返回后才提交的。这意味着，一个线程可能已经释放了锁，但事务还未提交。

6. 这里获取代理对象,是用Service接口类对象,而不是service实现类对象,需要回顾之前学习ssm的时候Spring的俩种AOP代理机制:JDK动态代理   和  CGLIB代理  
    1. JDK动态代理：当目标类（你的Service实现类）实现了至少一个接口时，Spring默认会使用JDK动态代理。此时代理对象会实现相同的业务接口（IVoucherOrderService），但不是实现类（VoucherOrderServiceImpl）的子类或实例。你可以把它想象成是原始实现类的一个“兄弟”，它们共同的“父亲”是那个接口。
    2. CGLIB代理：当目标类没有实现任何接口，或者强制配置了proxy-target-class=true时，Spring会使用CGLIB代理。此时代理对象会继承目标类（VoucherOrderServiceImpl），是它的一个子类。

在你的代码中，由于 IVoucherOrderService接口的存在，Spring 默认会使用JDK动态代理。

```java
 Long userId = UserHolder.getUser().getId();
        synchronized (userId.toString().intern()) {
            //获取代理对象（事务）
            IVoucherOrderService proxy = (IVoucherOrderService) AopContext.currentProxy();
            return proxy.createVoucherOrder(voucherId);
        }//调用封装  一人一单（悲观锁）  并且  不超卖（乐观锁）

```

7. 这里需要引入依赖包

```java
   <dependency>
            <groupId>org.aspectj</groupId>
            <artifactId>aspectjweaver</artifactId>
        </dependency>
    </dependencies>
```

并且在启动类上加上注解 `@EnableAspectJAutoProxy(exposeProxy = true)`

提示：exposeProxy = true 是该注解的一个可选属性，用于决定是否将代理对象暴露给 AopContext，以便在切面内部访问当前代理对象。默认情况下，exposeProxy 的值为 false，即不暴露当前代理。如果将 exposeProxy 设置为 true，可以通过 AopContext.currentProxy() 方法在切面内部获取当前代理对象。

#### 集群下的一人一单超卖问题
> 通过加锁可以解决在单机情况下的一人一单安全问题，但是在集群模式下就不行了。  
1、我们将服务启动两份，端口分别为8081和8082,ideal会分配俩个tomcat来启动
>

1）搭建集群并实现负载均衡

首先，在IDEA中启动两个SpringBoot程序，一个端口号是8081，另一个端口是8082：

![](/images/c0e571e31c51b5fec08f25276bd056f8.png)

然后在Nginx中配置负载均衡：

![](/images/51c489ceb2b833e04bf1a11485536a8f.png)

有关锁失效原因分析

![](/images/ba9df1cd84659010aa821ae3d8458224.png)

由于现在我们部署了多个tomcat，每个tomcat都有一个属于自己的jvm，那么假设在服务器A的tomcat内部，有两个线程，这两个线程由于使用的是同一份代码，那么他们的锁对象是同一个，是可以实现互斥的，但是如果现在是服务器B的tomcat内部，又有两个线程，但是他们的锁对象写的虽然和服务器A一样，但是锁对象却不是同一个，所以线程3和线程4可以实现互斥，但是却无法和线程1和线程2实现互斥，这就是 集群环境下，syn锁失效的原因，在这种情况下，我们就需要使用分布式锁来解决这个问题。

##### 分布式锁
> 使用一个分布锁，在整个系统的全局中设置一个锁监视器，从而保障不同节点的JVM都能够识别，从而实现集群下只允许一个线程访问一个代码块
>

分布式锁的常见实现方式：

1. 基于关系数据库：可以利用数据库的事务特性和唯一索引来实现分布式锁。通过向数据库插入一条具有唯一约束的记录作为锁，其他进程在获取锁时会受到数据库的并发控制机制限制。
2. 基于缓存（如Redis）：使用分布式缓存服务（如Redis）提供的原子操作来实现分布式锁。通过将锁信息存储在缓存中，其他进程可以通过检查缓存中的锁状态来判断是否可以获取锁。
3. 基于ZooKeeper：ZooKeeper是一个分布式协调服务，可以用于实现分布式锁。通过创建临时有序节点，每个请求都会尝试创建一个唯一的节点，并检查自己是否是最小节点，如果是，则表示获取到了锁。
4. 基于分布式算法：还可以利用一些分布式算法来实现分布式锁，例如Chubby、DLM（Distributed Lock Manager）等。这些算法通过在分布式系统中协调进程之间的通信和状态变化，实现分布式锁的功能。

redis指令:

```java
# 添加锁
setnx [key] [value]
# 为锁设置过期时间，超时释放，避免死锁
expire [key] [time]


# 这种方式更加推荐，因为将上面两个指令变成一个指令，从而保障指令的原子性
set [key] [value] ex [time] nx  
```

##### <font style="color:rgb(218, 211, 199);background-color:rgb(29, 31, 32);">分布式锁解决超卖问题</font>
![](/images/721587cb7f374c3d8eaa09c2f91f9c76.png)

###### 分布式锁 版本一
```java
public interface ILock {
    /**
     * 获取锁
     * @param timeoutSec  锁持有的超时时间，过期后自动释放锁
     * @return true 代表获取锁成功   false 代表获取锁失败
     */
    boolean tryLock(long timeoutSec);

    /**
     * 释放锁
     */
    void unLock();
}



public class SimpleRedisLock implements ILock{

     private  String name ;
        //给锁加上前缀  便于标识
     private static final String KEY_PREFIX="lock:";

     private StringRedisTemplate stringRedisTemplate;


     //构造器  用于将 name   stringRedisTemplate  注入进来
    public SimpleRedisLock(String name, StringRedisTemplate stringRedisTemplate) {
        this.name = name;
        this.stringRedisTemplate = stringRedisTemplate;
    }

    /**
     *
     * @param timeoutSec  锁持有的超时时间，过期后自动释放锁
     * @return
     */
    @Override
    public boolean tryLock(long timeoutSec) {
        // 获取线程标示
        String threadId = String.valueOf(Thread.currentThread().getId());
        // 获取锁
        Boolean success = stringRedisTemplate.opsForValue()
                .setIfAbsent(KEY_PREFIX + name, threadId, timeoutSec, TimeUnit.SECONDS);
        return Boolean.TRUE.equals(success);
        //因为返回值是boolean  success是包装类  存在自动拆箱
        // 防止success为空造成空指针异常
    }

    /**
     * 释放锁  释放锁，防止删除别人的锁
     */
    @Override
    public void unLock() {
        stringRedisTemplate.delete(KEY_PREFIX + name);
    }
}



```

![](/images/d2d6f2a36ebb52f5330f914d51db1f43.png)

使用锁

```java
        // 3、创建订单（使用分布式锁）
        Long userId = ThreadLocalUtls.getUser().getId();
        SimpleRedisLock lock = new SimpleRedisLock(stringRedisTemplate, "order:" + userId);
        boolean isLock = lock.tryLock(1200);
        if (!isLock) {
            // 索取锁失败，重试或者直接抛异常（这个业务是一人一单，所以直接返回失败信息）
            return Result.fail("一人只能下一单");
        }
        try {
            // 索取锁成功，创建代理对象，使用代理对象调用第三方事务方法， 防止事务失效
            IVoucherOrderService proxy = (IVoucherOrderService) AopContext.currentProxy();
            return proxy.createVoucherOrder(userId, voucherId);
        } finally {
            lock.unlock();
        }

```

实现细节:`try...finally...`确保发生异常时锁能够释放，注意这给地方不要使用`catch`，A事务方法内部调用B事务方法，A事务方法不能够直接catch，否则会导致事务失效

###### 分布式锁优化 一
> 本次优化主要解决了锁超时释放出现的超卖问题
>

上面实现的分布式锁会存在一个问题：当线程1获取锁后，由于业务阻塞，线程1的锁超时释放了，这时候线程2趁虚而入拿到了锁，然后此时线程1业务完成了，然后把线程2刚刚获取的锁给释放了，这时候线程3又趁虚而入拿到了锁，这就导致又出现了超卖问题！（但是这个在小项目（并发数不高）中出现的概率比较低，在大型项目（并发数高）情况下是有一定概率的）

![](/images/86aea25ef64e68aba31c0fd5107158b2.png)

备注：我们可以把锁的有效期降低一点，这样就能够测试上面哪种情况了(●’◡’●)

<font style="color:rgb(221, 212, 202);background-color:rgb(29, 31, 32);">为分布式锁添加一个线程标识，在释放锁时判断当前锁是否是自己的锁，是自己的就直接释放，不是自己的就不释放锁，从而解决多个线程同时获得锁的情况导致出现超卖</font>

![](/images/7ec0be586eaa4b7470bdc182d420ef85.png)

不需要修改业务代码,修改锁的实现:

```java
    /**
     * 获取锁
     *
     * @param timeoutSec 超时时间
     * @return
     */
    @Override
    public boolean tryLock(long timeoutSec) {
        String threadId = ID_PREFIX + Thread.currentThread().getId() + "";
        // SET lock:name id EX timeoutSec NX
        Boolean result = stringRedisTemplate.opsForValue()
                .setIfAbsent(KEY_PREFIX + name, threadId, timeoutSec, TimeUnit.SECONDS);
        return Boolean.TRUE.equals(result);
    }

    /**
     * 释放锁
     */
    @Override
    public void unlock() {
        // 判断 锁的线程标识 是否与 当前线程一致
        String currentThreadFlag = ID_PREFIX + Thread.currentThread().getId();
        String redisThreadFlag = stringRedisTemplate.opsForValue().get(KEY_PREFIX + name);
        if (currentThreadFlag != null || currentThreadFlag.equals(redisThreadFlag)) {
            // 一致，说明当前的锁就是当前线程的锁，可以直接释放
            stringRedisTemplate.delete(KEY_PREFIX + name);
        }
        // 不一致，不能释放
    }
}

```

###### 分布式锁优化二
> <font style="color:rgb(208, 199, 186);background-color:rgb(38, 42, 43);">主要解决释放锁时的原子性问题。说到底也是锁超时释放的问题</font>
>

优化一有可能发生超卖问题（出现超卖概率更低了）：当线程1获取锁，执行完业务然后并且判断完当前锁是自己的锁时，但就在此时发生了阻塞，结果锁被超时释放了，线程2立马就趁虚而入了，获得锁执行业务，但就在此时线程1阻塞完成，由于已经判断过锁，已经确定锁是自己的锁了，于是直接就删除了锁，结果删的是线程2的锁，这就又导致线程3趁虚而入了，从而继续发生超卖问题.

![](/images/a487655720793c0784079e3172c60317.png)

判断锁和释放锁在同一个方法中，并且两者之间没有别的代码，为什么会发生阻塞呢？JVM的垃圾回收机制会导致短暂的阻塞（我个人感觉这种情况发生的概率真的不高，但是我也没有实际接触过真正的大型高并发项目，所以具体也只能靠揣摩）

如何保障 判断锁 和 释放锁 这连段代码的原子性呢？答案是使用Lua脚本

那么Lua脚本是如何确保原子性的呢？Redis使用（支持）相同的Lua解释器，来运行所有的命令。Redis还保证脚本以原子方式执行：在执行脚本时，不会执行其他脚本或Redis命令。这个语义类似于MULTI（开启事务）/EXEC（触发事务，一并执行事务中的所有命令）。从所有其他客户端的角度来看，脚本的效果要么仍然不可见，要么已经完成。

注意：虽然Redis在单个Lua脚本的执行期间会暂停其他脚本和Redis命令，以确保脚本的执行是原子的，但如果Lua脚本本身出错，那么无法完全保证原子性。也就是说Lua脚本中的Redis指令出错，会发生回滚以确保原子性，但Lua脚本本身出错就无法保障原子性

先在resources下定义好lua脚本

```java

-- 比较缓存中的线程标识与当前线程标识是否一致
if (redis.call('get', KEYS[1]) == ARGV[1]) then
    -- 一致，直接删除
    return redis.call('del', KEYS[1])
end
-- 不一致，返回0
return 0

```

`RedisTemplate`中，可以利用`execute`方法去执行`lua`脚本，参数对应关系就如下图

![](/images/6887e45e93d173b84c41f573b98a3851.png)

```java
//提前初始化脚本，避免每次去执行脚本时单独去创建脚本对象
private static final DefaultRedisScript<Long> UNLOCK_SCRIPT;
    static {
        UNLOCK_SCRIPT = new DefaultRedisScript<>();
        UNLOCK_SCRIPT.setLocation(new ClassPathResource("unlock.lua"));
        UNLOCK_SCRIPT.setResultType(Long.class);
    }
//用lua脚本来保持分布式锁的原子性
public void unlock() {
    // 调用lua脚本
    stringRedisTemplate.execute(
            UNLOCK_SCRIPT,
            Collections.singletonList(KEY_PREFIX + name),
            ID_PREFIX + Thread.currentThread().getId());
}
经过以上代码改造后，我们就能够实现 拿锁比锁删锁的原子性动作了~

```



总结:  
基于Redis的分布式锁实现思路：

+ 利用set nx ex获取锁，并设置过期时间，保存线程标示
+ 释放锁时先判断线程标示是否与自己一致，一致则删除锁

特性：

+ 利用set nx满足互斥性
+ 利用set ex保证故障时锁依然能释放，避免死锁，提高安全性
+ 利用Redis集群保证高可用和高并发特性

利用添加过期时间，防止死锁问题的发生，但是有了过期时间之后，可能出现误删别人锁的问题，这个问题我们开始是利用删之前 通过拿锁，比锁，删锁这个逻辑来解决的，也就是删之前判断一下当前这把锁是否是属于自己的，但是现在还有原子性问题，也就是我们没法保证拿锁比锁删锁是一个原子性的动作，最后通过lua表达式来解决这个问题



###### Redission 实现分布式锁
> Redssion是一个十分成熟的Redis框架，功能也很多，比如：分布式锁和同步器、分布式对象、分布式集合、分布式服务，各种Redis实现分布式的解决方案。
>

Redisson就是一个使用Redis解决分布式问题的方案的集合，当然它不仅仅是解决分布式相关问题，还包含其它的一些问题。

分布式锁的究极优化就是使用别人造好的轮子............



之前使用Lua的优化方式仍有如下问题:

+ <font style="background-color:#FBDE28;">分布式锁不可重入</font>：重入问题是指 获得锁的线程可以再次进入到相同的锁的代码块中，可重入锁的意义在于防止死锁，比如HashTable这样的代码中，他的方法都是使用synchronized修饰的，假如他在一个方法内，调用另一个方法，那么此时如果是不可重入的，不就死锁了吗？所以可重入锁他的主要意义是防止死锁，我们的synchronized和Lock锁都是可重入的。
+ <font style="background-color:#FBDE28;">分布式锁不可重试</font>：获取锁只尝试一次就返回false，没有重试机制，这会导致数据丢失，比如线程1获取锁，然后要将数据写入数据库，但是当前的锁被线程2占用了，线程1直接就结束了而不去重试，这就导致数据发生了丢失
+ <font style="background-color:#FBDE28;">分布式锁超时释放</font>：超时释放机机制虽然一定程度避免了死锁发生的概率，但是如果业务执行耗时过长，期间锁就释放了，这样存在安全隐患。锁的有效期过短，容易出现业务没执行完就被释放，锁的有效期过长，容易出现死锁，所以这是一个大难题！

我们可以设置一个较短的有效期，但是加上一个 心跳机制 和 自动续期：在锁被获取后，可以使用心跳机制并自动续期锁的持有时间。通过定期发送心跳请求，显示地告知其他线程或系统锁还在使用中，同时更新锁的过期时间。如果某个线程持有锁的时间超过了预设的有效时间，其他线程可以尝试重新获取锁。

+ <font style="background-color:#FBDE28;">主从一致性问题</font>：如果`Redis`提供了主从集群，当我们向集群写数据时，主机需要异步的将数据同步给从机，而万一在同步过去之前，主机宕机了，就会出现死锁问题



1. 引入Redisson依赖

```plain
    <dependency>
        <groupId>org.redisson</groupId>
        <artifactId>redisson</artifactId>
        <version>3.13.6</version>
    </dependency>
```

2. 配置Redisson客户端

```java
@Configuration
public class RedissonConfig {
    @Value("${spring.redis.host}")
    private String host;
    @Value("${spring.redis.port}")
    private String port;
    @Value("${spring.redis.password}")
    private String password;

    /**
 * 创建Redisson配置对象，然后交给IOC管理
 *
 * @return
 */
    @Bean
    public RedissonClient redissonClient() {
        // 获取Redisson配置对象
        Config config = new Config();
        // 添加redis地址，这里添加的是单节点地址，也可以通过 config.userClusterServers()添加集群地址
        config.useSingleServer().setAddress("redis://" + this.host + ":" + this.port)
        .setPassword(this.password);
        // 获取RedisClient对象，并交给IOC进行管理
        return Redisson.create(config);
    }
}
```

  
温馨提示：此外还有一种引入方式，可以引入 redission 的 starter 依赖，然后在yml文件中配置Redisson，但是不推荐这种方式，因为他会替换掉 Spring官方 提供的这套对 Redisson 的配置

3. 业务修改

```java
 		Long userId = UserHolder.getUser().getId();
        //创建锁对象 这个代码不用了，因为我们现在要使用分布式锁
        //SimpleRedisLock lock = new SimpleRedisLock("order:" + userId, stringRedisTemplate);
        RLock lock = redissonClient.getLock("lock:order:" + userId);
        //获取锁对象
        boolean isLock = lock.tryLock();
       
		//加锁失败
        if (!isLock) {
            return Result.fail("不允许重复下单");
        }
        try {
            //获取代理对象(事务)
            IVoucherOrderService proxy = (IVoucherOrderService) AopContext.currentProxy();
            return proxy.createVoucherOrder(voucherId);
        } finally {
            //释放锁
            lock.unlock();
        }

```

###### Redission可重入锁的原理:  
![](/images/57dd4a1d3d45ff024412b65ed2a5a00e.png)
Redisson内部释放锁，并不是直接执行`del`命令将锁给删除，而是将锁以`hash`数据结构的形式存储在Redis中，每次获取锁，都将`value`的值+1，每次释放锁，都将value的值-1，只有锁的value值归0时才会真正的释放锁，从而确保锁的可重入性.



源码解析:

![](/images/bf71ce3f324c51efe272d05b42219840.png)

调用 redission的 lock对象中的 tryLock() 方法来尝试获取锁，该方法进行了重写：

        1）boolean tryLock()：当获取锁失败时，默认不等待，就是不重试获取锁，默认锁的超时时间为 30 秒。

        2）boolean tryLock(long time, TimeUnit unit)：在 time 时间内会进行重试尝试获取锁，unit 为时间单位。默认锁的超时时间为 30 秒。

        3）boolean tryLock(long waitTime, long leaseTime, TimeUnit unit)：在获取锁失败时，在 waitTime 时间内进行重试尝试获取锁，锁的超时时间为 leaseTime 秒，unit 为时间单位。

![](/images/8e4e389cb4dd948f71824dbf81c19d9c.png)

tryAcquire底层是基于获取锁的Lua脚本:

```python
-- KEYS[1]: 锁名称
-- ARGV[1]: 锁过期时间（默认30秒）
-- ARGV[2]: 线程标识（UUID:ThreadId）

-- 1. 检查锁是否存在
if (redis.call('exists', KEYS[1]) == 0) then
    -- 2. 不存在则创建锁，初始重入次数为1
    redis.call('hset', KEYS[1], ARGV[2], 1);
    -- 3. 设置过期时间
    redis.call('pexpire', KEYS[1], ARGV[1]);
    -- 获取锁成功
    return nil;
end;

-- 4. 锁已存在，检查是否被当前线程持有
if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then
    -- 5. 是当前线程持有，则重入次数+1
    redis.call('hincrby', KEYS[1], ARGV[2], 1);
    -- 6. 重置过期时间
    redis.call('pexpire', KEYS[1], ARGV[1]);
    return nil;
end;

-- 7. 锁被其他线程持有，返回剩余过期时间
return redis.call('pttl', KEYS[1]);

```

流程 ： 先判断缓存中是否存在 key 字段，如果存在，则说明锁已经被成功获取，这时候需要继续判断成功获取锁的对象是否为当前线程，如果根据 key field 来判断是当前线程，则 value += 1 且还需要重置锁的超时时间；如果根据 key field 判断不是当前线程，则直接返回 null。如果缓存中不存在 key 字段，则说明锁还没有被其他线程获取，则获取锁成功。

![](/images/8e4e389cb4dd948f71824dbf81c19d9c.png)

当 ttl == null ，则说明当前线程成功获取锁，因此就不需要接着往下再次尝试去获取锁了。相反，当 ttl != null ，则需要接着往下走，重新尝试去获取锁。

        判断 time 等于当前时间减去在第一次获取锁之前的时间，time 也就是最大的等待时间还剩多少。判断 time 是否小于 0 ，若小于 0 则已经到了最大等待时间了，所以不需要再继续等下去了，直接返回 false 即可。

        若 time 还是大于 0 ，则接着往下走：

![](/images/70e88cdd3d9a16cf5d6d04109f9ab049.png)

**<font style="color:rgb(221, 212, 202);background-color:rgb(29, 31, 32);">调用 subscribe 方法，该方法可以理解成订阅锁，一旦锁被释放之后，该方法就会收到通知，然后再去尝试获取锁。</font>**

**<font style="color:rgb(221, 212, 202);background-color:rgb(29, 31, 32);">回顾在释放锁的时候，使用 Redis 命令中的 redis.call('publish', KEYS[2], ARGV[1]) 来发布消息，通知锁已经被释放，一旦锁被释放，那么就可以成功订阅</font>**

接着往下走，当在 time 时间内订阅锁成功，会更新 time 时间，也就是更新最大的等待时间，判断 time 小于 0 ，则返回 false ，如果 time 还是大于 0 ，则到了真正尝试第二次获取锁，调用 tryAcquire(waitTime, leaseTime, unit, threadId) 方法，将返回值再次赋值给变量 ttl ，判断 ttl == null ，则说明成功获取锁了，直接返回 true ；判断 ttl != null ，则第二次获取锁还是失败，由需要更新 time 了，因为在调用尝试获取锁的过程中，消耗时间还是挺大的，同理，判断更新完之后的 time 是否大于 0，如果 time 小于 0，则超过了剩余最大锁的超时时间，返回 false ；



![](/images/633565dac2d1a3c9404a7a1453f5a2df.png)

如果判断 time 仍旧大于 0 ：

        那么先判断锁的过期时间 ttl 与 剩余时间 time ，如果 ttl < time ，则类似订阅方法一样的思路，选择等待 ttl 锁的过期时间，当 ttl 过期之后，就会订阅该锁；如果 time < ttl ，则 ttl 还没有释放，就不需要等 ttl 了，等到 time 结束还没有订阅到锁，则 time 也就小于 0 了，如果在 time 时间内获取到锁，再次尝试去获取锁，同样的，当在 ttl 时间内，成功订阅了，而且 time > 0 ，则会第三次去尝试获取锁。之后的步骤都是如此，这里使用了 do whlie 循环，判断循环成立为 time > 0，当 time < 0 ，则会退出循环。

![](/images/faf5dc1ed3c3b8c4d55799844aad3ce7.png)

<font style="color:rgb(221, 212, 202);background-color:rgb(29, 31, 32);">总结，在解决可重试锁过程中，并不是循环不断的调用 tryAcquire(waitTime, leaseTime, unit, threadId) 方法来获取锁，这样容易造成 CPU 的浪费，而是通过等待锁释放，再去获取锁的方式来实现的可重试锁，利用信号量（Semaphore）和发布/订阅（PubSub）模式实现等待、唤醒、获取锁失败的重试机制。</font>



###### <font style="color:rgb(218, 211, 199);background-color:rgb(29, 31, 32);">Redisson WatchDog 机制 解决超时释放问题</font>
**<font style="color:rgb(221, 212, 202);background-color:rgb(29, 31, 32);">解决超时释放的核心是：当 leaseTime == -1 时，为了保证当前业务执行完毕才能释放锁，而不是业务还没有执行完毕，锁就被自动释放了。</font>**

**<font style="color:rgb(221, 212, 202);background-color:rgb(29, 31, 32);">追踪源代码：</font>**

**<font style="color:rgb(221, 212, 202);background-color:rgb(29, 31, 32);">当 leaseTime == -1 时，默认锁的最大超时时间为 30 秒，会执行以下代码。</font>**

![](/images/579b76de5b0678102729e541c738a698.png)

![](/images/beaef716098b76ed7f6a629210daa767.png)

![](/images/d2ec4593b3c9377adb674035b71677fa.png)

WatchDog 会在锁的过期时间到期之前，定期向 Redis 发送续约请求，更新锁的过期时间。这通常是通过设置一个较短的过期时间和一个续约间隔来实现的。

        如果持有锁的线程正常释放锁，WatchDog 会停止续约操作。如果持有锁的线程崩溃或失去响应，WatchDog 会在锁的过期时间到达后自动释放锁

![](/images/d3547043d8208f500fd387f201c51a4e.png)

WatchDog 机制：在获取锁成功之后，就会调用 scheduleExpirationRenewal(threadId) 方法开启自动续约，具体是由在 map 中添加业务名称和任务定时器，这个定时器会在一定时间内执行，比如说 10 秒就会自动开启任务，而该定时器中的任务就是不断的重置锁的最大超时时间，使用递归，不断的调用重置锁的时间，这就保证了锁是永久被当前线程持有。 

        这样就可以保证执行业务之后，才会释放锁。释放锁之后，会取消定时任务。

###### <font style="color:rgb(218, 211, 199);background-color:rgb(29, 31, 32);">Redisson MultiLock 结局主从一致性问题</font>
在集群的 Redis 中会区分出主力机和一般机器，在写 Redis 命令会放到主力机中运行，而主力机和一般机器需要保证数据都是一样的，也就是主从同步数据，在主力机中执行写命令时，突然发生宕机，未来得及将数据同步到其他一般机器中，而且当主力机宕机之后，会选出一台一般机器充当主力机，这时候的主力机没有同步之前的数据，那么其他线程再来写命名的时候就会出现问题了，这出现了主从不一致性。

![](/images/f6bc598bd5b02440f239b6814f555646.png)

在多主架构中，每台主机都可以接收写请求，这样即使某一台主机宕机，其他主机仍然可以继续处理写请求。

        当某一台主机宕机后，如果在它恢复之前有新的写操作发生，可能会导致数据不一致。通过比较不同主机的数据状态，可以很容易地发现这些不一致的问题。

        当宕机的主机恢复后，可以通过与其他主机的数据进行比较，找出差异并进行数据同步，确保所有主机的数据一致。

        简单来说，设置多台主力机，每一次写命令都是一式多份，当某一台主力机出现宕机了，主从未来得及同步时，再写命令，同样一式多份，这样充当主力机出现了跟其他主力机不同的结果时，就很容易的发现问题了。

        通过设置多台主力机并进行写操作的多份复制，可以有效提高系统的可靠性，并在出现问题时快速发现和解决数据不一致的问题

![](/images/6a7471d456e40210a3990846f5c4f8eb.png)

具体使用：![](/images/38c0ed6aa705bd659e273028e6ea3c3a.png)



总结：

+ 如何解决可重入问题：利用hash结构记录线程id和重入次数。
+ 如何解决可重试问题：利用信号量和PubSub功能实现等待、唤醒，获取锁失败的重试机制。
+ 如何解决超时续约问题：利用watchDog，每隔一段时间（releaseTime / 3），重置超时时间。
+ 如何解决主从一致性问题：利用Redisson的multiLock，多个独立的Redis节点，必须在所有节点都获取重入锁，才算获取锁成功

缺陷：运维成本高、实现复杂

### 秒杀优化
#### 异步秒杀优化
> 异步（Asynchronous）是指程序在执行任务时，不需要等待当前任务完成，而是在任务执行的同时继续执行其他任务。在异步模式下，任务的执行顺序是不确定的，程序通过回调、事件通知等方式来获取任务执行的结果。
>
> 显然异步的性能是要高于同步的，但是会牺牲掉一定的数据一致性，所以也不是无脑用异步，要根据具体业务进行分析，这里的下单是可以使用异步的，因为下单操作比较耗时，后端操作步骤多，可以进行拆分
>

之前的业务流程：

![](/images/3b8aaf19865e13fbc0fb73f1577c6028.png)

现在我们可以将一部分的工作交给Redis，并且不能直接去调用Redis，而是通过开启一个独立的子线程去异步执行，从而大大提高效率

![](/images/ddf3dcd5cba0d7b7fd22d148785d0ddc.png)![](/images/0b5e15f05329a89ab1c72ad953cff52c.png)

![](/images/9602296f77788b251d54e3fc6cfb25a6.png)

![](/images/39aa9886d0b8205c6b16f33544203228.png)

1. 库存判断放到Redis中，我们应该使用哪一种数据结构存储订单的库存呢？可以直接使用 `<font style="color:rgb(255, 88, 132);background-color:rgb(50, 24, 31);">String</font>` 类型的数据结构，Redis的IO操作是单线程的，所以能够充分保障线程安全。
2. 一人一单的判断也是由Redis完成的，所以我们需要在Redis中存储订单信息，而订单是唯一的，所以我们可以使用 Set类型的数据结构
3. lua脚本中，接收的参数都是String类型的，String类型的数据无法进行比较，我们需要利用tonumber函数将String转成Number
4. stringRedisTemplate.execute这个方法，第二个参数是应该List集合，标识传入Lua脚本中的的 key，如果我们没有传key，那么直接使用Collections.emptyList()，而不是直接使用null，是因为在 stringRedisTemplate.execute 方法内部可能对参数进行了处理，如果传递 null 可能引发NPE异常
5. 异步线程无法从ThreadLocal中获取userId，我们需要从voucherOrder中获取userId
6. AopContext.currentProxy()底层也是利用ThreadLocal获取的，所以异步线程中也无法使用。解决方案有两种，第一种是将代理对象和订单一起放入阻塞队列中，第二种是将代理对象的作用域提升，变成一个成员变量（我采用了第二种方式）

首先编写LUA脚本：

```python

--- Description 判断库存是否充足 && 判断用户是否已下单
---
-- 优惠券id
local voucherId = ARGV[1];
-- 用户id
local userId = ARGV[2];

-- 库存的key
local stockKey = 'seckill:stock:' .. voucherId;
-- 订单key
local orderKey = 'seckill:order:' .. voucherId;

-- 判断库存是否充足 get stockKey > 0 ?
local stock = redis.call('GET', stockKey);
if (tonumber(stock) <= 0) then
    -- 库存不足，返回1
    return 1;
end

-- 库存充足，判断用户是否已经下过单 SISMEMBER orderKey userId
if (redis.call('SISMEMBER', orderKey, userId) == 1) then
    -- 用户已下单，返回2
    return 2;
end

-- 库存充足，没有下过单，扣库存、下单
redis.call('INCRBY', stockKey, -1);
redis.call('SADD', orderKey, userId);
-- 返回0，标识下单成功
return 0;

```

主要的VounvherOrderServiceImpl代码：

```java
@Service
public class VoucherOrderServiceImpl extends ServiceImpl<VoucherOrderMapper, VoucherOrder> implements IVoucherOrderService {

    @Resource
    private ISeckillVoucherService seckillVoucherService;

    @Resource
    private RedisIdWorker redisIdWorker;

    @Resource
    private StringRedisTemplate stringRedisTemplate;

    @Resource
    private RedissonClient redissonClient;

    /**
     * 当前类初始化完毕就立马执行该方法
     */
    @PostConstruct
    private void init() {
        // 执行线程任务
        SECKILL_ORDER_EXECUTOR.submit(new VoucherOrderHandler());
    }

    /**
     * 存储订单的阻塞队列
     */
    private BlockingQueue<VoucherOrder> orderTasks = new ArrayBlockingQueue<>(1024 * 1024);

    /**
     * 线程池
     */
    private static final ExecutorService SECKILL_ORDER_EXECUTOR = Executors.newSingleThreadExecutor();

    /**
     * 线程任务: 不断从阻塞队列中获取订单
     */
    private class VoucherOrderHandler implements Runnable {
        @Override
        public void run() {
            while (true) {
                // 从阻塞队列中获取订单信息，并创建订单
                try {
                    VoucherOrder voucherOrder = orderTasks.take();
                    handleVoucherOrder(voucherOrder);
                } catch (Exception e) {
                    log.error("处理订单异常", e);
                }
            }
        }
    }

    /**
     * 创建订单
     *
     * @param voucherOrder
     */
    private void handleVoucherOrder(VoucherOrder voucherOrder) {
        Long userId = voucherOrder.getUserId();
        RLock lock = redissonClient.getLock(RedisConstants.LOCK_ORDER_KEY + userId);
        boolean isLock = lock.tryLock();
        if (!isLock) {
            // 索取锁失败，重试或者直接抛异常（这个业务是一人一单，所以直接返回失败信息）
            log.error("一人只能下一单");
            return;
        }
        try {
            // 创建订单（使用代理对象调用，是为了确保事务生效）
            proxy.createVoucherOrder(voucherOrder);
        } finally {
            lock.unlock();
        }
    }

    /**
     * 加载 判断秒杀券库存是否充足 并且 判断用户是否已下单 的Lua脚本
     */
    private static final DefaultRedisScript<Long> SECKILL_SCRIPT;
    static {
        SECKILL_SCRIPT = new DefaultRedisScript<>();
        SECKILL_SCRIPT.setLocation(new ClassPathResource("lua/seckill.lua"));
        SECKILL_SCRIPT.setResultType(Long.class);
    }

    /**
     * VoucherOrderServiceImpl类的代理对象
     * 将代理对象的作用域进行提升，方面子线程取用
     */
    private IVoucherOrderService proxy;

    /**
     * 抢购秒杀券
     *
     * @param voucherId
     * @return
     */
    @Transactional
    @Override
    public Result seckillVoucher(Long voucherId) {
        // 1、执行Lua脚本，判断用户是否具有秒杀资格
        Long result = null;
        try {
            result = stringRedisTemplate.execute(
                SECKILL_SCRIPT,
                Collections.emptyList(),
                voucherId.toString(),
                ThreadLocalUtls.getUser().getId().toString()
            );
        } catch (Exception e) {
            log.error("Lua脚本执行失败");
            throw new RuntimeException(e);
        }
        if (result != null && !result.equals(0L)) {
            // result为1表示库存不足，result为2表示用户已下单
            int r = result.intValue();
            return Result.fail(r == 2 ? "不能重复下单" : "库存不足");
        }
        // 2、result为0，用户具有秒杀资格，将订单保存到阻塞队列中，实现异步下单
        long orderId = redisIdWorker.nextId(SECKILL_VOUCHER_ORDER);
        // 创建订单
        VoucherOrder voucherOrder = new VoucherOrder();
        voucherOrder.setId(orderId);
        voucherOrder.setUserId(ThreadLocalUtls.getUser().getId());
        voucherOrder.setVoucherId(voucherId);
        // 将订单保存到阻塞队列中
        orderTasks.add(voucherOrder);
        // 索取锁成功，创建代理对象，使用代理对象调用第三方事务方法， 防止事务失效
        IVoucherOrderService proxy = (IVoucherOrderService) AopContext.currentProxy();
        this.proxy = proxy;
        return Result.ok();
    }

    /**
     * 创建订单
     *
     * @param voucherOrder
     * @return
     */
    @Transactional
    @Override
    public void createVoucherOrder(VoucherOrder voucherOrder) {
        Long userId = voucherOrder.getUserId();
        Long voucherId = voucherOrder.getVoucherId();
        // 1、判断当前用户是否是第一单
        int count = this.count(new LambdaQueryWrapper<VoucherOrder>()
                .eq(VoucherOrder::getUserId, userId));
        if (count >= 1) {
            // 当前用户不是第一单
            log.error("当前用户不是第一单");
            return;
        }
        // 2、用户是第一单，可以下单，秒杀券库存数量减一
        boolean flag = seckillVoucherService.update(new LambdaUpdateWrapper<SeckillVoucher>()
                .eq(SeckillVoucher::getVoucherId, voucherId)
                .gt(SeckillVoucher::getStock, 0)
                .setSql("stock = stock -1"));
        if (!flag) {
            throw new RuntimeException("秒杀券扣减失败");
        }
        // 3、将订单保存到数据库
        flag = this.save(voucherOrder);
        if (!flag) {
            throw new RuntimeException("创建秒杀券订单失败");
        }
    }
}

```

#### 消息队列优化  
消息队列具体流程：

![](/images/b35a08547845fec2a4d989f42793aa89.png)

![](/images/02192124276f625ae28827318fdc3970.png)

##### List结构实现消息队列 ：  
队列是入口和出口不在一边，因此我们可以利用：LPUSH 结合 RPOP、或者 RPUSH 结合 LPOP来实现。
不过要注意的是，当队列中没有消息时RPOP或LPOP操作会返回null，并不像JVM的阻塞队列那样会阻塞并等待消息。因此这里应该使用BRPOP或者BLPOP，该指令可以实现阻塞效果。

优点：

+ 利用Redis存储，不受限于JVM内存上限
+ 基于Redis的持久化机制，数据安全性有保证
+ 可以满足消息有序性

缺点：

+ 无法避免消息丢失
+ 只支持单消费者

##### PubSub消息队列：
redis 指令参考：

+ SUBSCRIBE channel [channel] ：订阅一个或多个频道
+ PUBLISH channel msg ：向一个频道发送消息
+ PSUBSCRIBE pattern[pattern] ：订阅与pattern格式匹配的所有频道

![](/images/158cebc0790fe354e537dcbbe38d919e.png)



##### 基于Stream实现消息队列
redis指令参考：

发送消息  xadd  

![](/images/b0d3ca39a2a4c86f5e1b2955b18018e9.png)

key：队列名称

读取消息 XREAD

![](/images/8075584f5f826f897eae4fe9814aa434.png)

循环调用XREAD阻塞式实现查询最新消息，来实现持续监听队列的效果

![](/images/6ca59197b9a6216277e1c02361592168.png)

上面的指令中的￥，代表读取队列中的最新消息，并发到达 的消息就会被遗漏掉

XREAD命令特点：

+ 消息可回溯
+ 一个消息可以被多个消费者读取
+ 可以阻塞读取
+ 有消息漏读的风险

消费者组方式：将多个消费者划分到一个组中，监听同一个队列

![](/images/0e5adc61889fa42b3e71a42fcc1346c5.png)

redis指令参考:

创建消费者 XGROUP

XGROUP CREATE key group ID [MKSTREAM] 

删除消费者组：

XGROUPDESTORY key groupName

添加消费者组：

XGROUPCREATECONSUMER key groupname consumername

删除指定消费者:

XGROUPDELCONSUMER key groupname consumername

从消费者组读取信息：

XREADGROUP GROUP group consumer [COUNT count] [BLOCK milliseconds] [NOACK] STREAMS key [key ...] ID [ID ...]

参数：

key：队列名称  
group：消费者组名称  
ID：起始ID标示，$代表队列中最后一个消息，0则代表队列中第一个消息  
MKSTREAM：队列不存在时自动创建队列

+ consumer：消费者名称，如果消费者不存在，会自动创建一个消费者
+ count：本次查询的最大数量
+ BLOCK milliseconds：当没有消息时最长等待时间
+ NOACK：无需手动ACK，获取到消息后自动确认
+ STREAMS key：指定队列名称
+ ID：获取消息的起始ID
        * 如果ID为“>”则从下一个未消费的消息开始
        * 其它：根据指定id从pending-list中获取已消费但未确认的消息，例如0，是从pending-list中的第一个消息开始

![](/images/22010a98453f39f358a00dba16d2a919.png)



```java
private class VoucherOrderHandler implements Runnable {

    @Override
    public void run() {
        while (true) {
            try {
                // 1.获取消息队列中的订单信息 XREADGROUP GROUP g1 c1 COUNT 1 BLOCK 2000 STREAMS s1 >
                List<MapRecord<String, Object, Object>> list = stringRedisTemplate.opsForStream().read(
                    Consumer.from("g1", "c1"),
                    StreamReadOptions.empty().count(1).block(Duration.ofSeconds(2)),
                    StreamOffset.create("stream.orders", ReadOffset.lastConsumed())
                );
                // 2.判断订单信息是否为空
                if (list == null || list.isEmpty()) {
                    // 如果为null，说明没有消息，继续下一次循环
                    continue;
                }
                // 解析数据
                MapRecord<String, Object, Object> record = list.get(0);
                Map<Object, Object> value = record.getValue();
                VoucherOrder voucherOrder = BeanUtil.fillBeanWithMap(value, new VoucherOrder(), true);
                // 3.创建订单
                createVoucherOrder(voucherOrder);
                // 4.确认消息 XACK
                stringRedisTemplate.opsForStream().acknowledge("s1", "g1", record.getId());
            } catch (Exception e) {
                log.error("处理订单异常", e);
                //处理异常消息
                handlePendingList();
            }
        }
    }

    private void handlePendingList() {
        while (true) {
            try {
                // 1.获取pending-list中的订单信息 XREADGROUP GROUP g1 c1 COUNT 1 BLOCK 2000 STREAMS s1 0
                List<MapRecord<String, Object, Object>> list = stringRedisTemplate.opsForStream().read(
                    Consumer.from("g1", "c1"),
                    StreamReadOptions.empty().count(1),
                    StreamOffset.create("stream.orders", ReadOffset.from("0"))
                );
                // 2.判断订单信息是否为空
                if (list == null || list.isEmpty()) {
                    // 如果为null，说明没有异常消息，结束循环
                    break;
                }
                // 解析数据
                MapRecord<String, Object, Object> record = list.get(0);
                Map<Object, Object> value = record.getValue();
                VoucherOrder voucherOrder = BeanUtil.fillBeanWithMap(value, new VoucherOrder(), true);
                // 3.创建订单
                createVoucherOrder(voucherOrder);
                // 4.确认消息 XACK
                stringRedisTemplate.opsForStream().acknowledge("s1", "g1", record.getId());
            } catch (Exception e) {
                log.error("处理pendding订单异常", e);
                try{
                    Thread.sleep(20);
                }catch(Exception e){
                    e.printStackTrace();
                }
            }
        }
    }
}


```

### set实现一人一赞
![](/images/7aa68ef469a7e190a3bac9762256a3b9.png)

`<font style="color:rgb(255, 255, 255);background-color:rgb(32, 36, 37);">Set</font>`<font style="color:rgb(255, 255, 255);background-color:rgb(29, 31, 32);"> 是一个无序且唯一的字符串元素集合，类似于 Python 中的集合。</font>

![](/images/66d9dcb574c0a27fd928382b6514615d.jpeg)

Set类型的数据结构具有

1. 不重复，符合业务的特点，一个用户只能点赞一次
2. 高性能，Set集合内部实现了高效的数据结构(Hash表)
3. 灵活性，Set集合可以实现一对多，一个用户可以点赞多个博客，符合实际的业务逻辑

也可以选择使用`Hash`（Hash占用空间比Set更小），如果想要点赞排序也可以选用`Sorted Set`

实现步骤:

将包含blog的id作为key，将用户id作为value存入redis，在初次进行点赞的同时，将blog的id和用户id存进redis，并且操作数据库进行like字段+1操作，相反，同一用户再进行点赞的时候， 先会从redis根据key去读用户的id，如果存在，则点赞取消，删除redis的缓存，并且操作数据库进行like字段减一操作



![](/images/80a3c55ff39b63fc6885698d892092de.png)



```java

@Service
public class BlogServiceImpl extends ServiceImpl<BlogMapper, Blog> implements IBlogService {

    @Resource
    private IUserService userService;

    @Resource
    private StringRedisTemplate stringRedisTemplate;

    /**
     * 根据id查询博客
     *
     * @param id
     * @return
     */
    @Override
    public Result queryBlogById(Long id) {
        // 查询博客信息
        Blog blog = this.getById(id);
        if (Objects.isNull(blog)) {
            return Result.fail("笔记不存在");
        }
        // 查询blog相关的用户信息
        queryUserByBlog(blog);
        // 判断当前用户是否点赞该博客
        isBlogLiked(blog);
        return Result.ok(blog);
    }

    /**
     * 判断当前用户是否点赞该博客
     */
    private void isBlogLiked(Blog blog) {
        Long userId = ThreadLocalUtls.getUser().getId();
        String key = BLOG_LIKED_KEY + blog.getId();
        Boolean isMember = stringRedisTemplate.opsForSet().isMember(key, userId.toString());
        blog.setIsLike(BooleanUtil.isTrue(isMember));
    }

    /**
     * 查询热门博客
     *
     * @param current
     * @return
     */
    @Override
    public Result queryHotBlog(Integer current) {
        // 根据用户查询
        Page<Blog> page = this.query()
                .orderByDesc("liked")
                .page(new Page<>(current, SystemConstants.MAX_PAGE_SIZE));
        // 获取当前页数据
        List<Blog> records = page.getRecords();
        // 查询用户
        records.forEach(blog -> {
            this.queryUserByBlog(blog);
            this.isBlogLiked(blog);
        });
        return Result.ok(records);
    }

    /**
     * 点赞
     *
     * @param id
     * @return
     */
    @Override
    public Result likeBlog(Long id) {
        // 判断用户是否点赞
        Long userId = ThreadLocalUtls.getUser().getId();
        String key = BLOG_LIKED_KEY + blog.getId();
        // sismember key value
        Boolean isMember = stringRedisTemplate.opsForSet().isMember(key, userId.toString());
        boolean result;
        if (BooleanUtil.isFalse(isMember)) {
            // 用户未点赞，点赞数+1
            result = this.update(new LambdaUpdateWrapper<Blog>()
                    .eq(Blog::getId, id)
                    .setSql("liked = liked + 1"));
            if (result) {
                // 数据库更新成功，更新缓存  sadd key value
                stringRedisTemplate.opsForSet().add(key, userId.toString());
            }
        } else {
            // 用户已点赞，点赞数-1
            result = this.update(new LambdaUpdateWrapper<Blog>()
                    .eq(Blog::getId, id)
                    .setSql("liked = liked - 1"));
            if (result) {
                // 数据更新成功，更新缓存 srem key value
                stringRedisTemplate.opsForSet().remove(key, userId.toString());
            }
        }
        return Result.ok();
    }

    /**
     * 查询博客相关用户信息
     *
     * @param blog
     */
    private void queryUserByBlog(Blog blog) {
        Long userId = blog.getUserId();
        User user = userService.getById(userId);
        blog.setName(user.getNickName());
        blog.setIcon(user.getIcon());
    }
}

```

### SortedSet实现点赞排行榜
`Sorted Set`结合了哈希表和跳跃表（Skip List）的特性，既可以像哈希表一样快速查找某个成员，又可以根据分数对成员进行排序。这种数据结构使得有序集合在处理需要排序和范围查询的场景中非常高效，成员的排名默认是按照分数从小到大排列的，即分数越小排名越靠前。

Redis 内部使用跳跃表（Skip List）和哈希表（Hash Table）来实现有序集合。跳跃表用于维护成员的有序性，哈希表用于快速查找成员。当执行 `ZADD` 命令时，Redis 会先检查哈希表中是否已经存在该成员，如果不存在，则在跳跃表中插入新的节点，并更新哈希表；如果存在，则根据可选参数决定是更新分数还是忽略该操作。

点赞查询列表的实现:

```java
@Override
public Result queryBlogLikes(Long id) {
    String key = BLOG_LIKED_KEY + id;
    // 1.查询top5的点赞用户 zrange key 0 4
    Set<String> top5 = stringRedisTemplate.opsForZSet().range(key, 0, 4);
    if (top5 == null || top5.isEmpty()) {
        return Result.ok(Collections.emptyList());
    }
    // 2.解析出其中的用户id
    List<Long> ids = top5.stream().map(Long::valueOf).collect(Collectors.toList());
    String idStr = StrUtil.join(",", ids);
    // 3.根据用户id查询用户 WHERE id IN ( 5 , 1 ) ORDER BY FIELD(id, 5, 1)
    List<UserDTO> userDTOS = userService.query()        // ① 开始构建查询
            .in("id", ids)                             // ② 条件：WHERE id IN (id1, id2, id3...)
            .last("ORDER BY FIELD(id," + idStr + ")")   // ③ 关键！自定义排序规则
            .list()                                     // ④ 执行查询，获取用户实体列表
            .stream()                                   // ⑤ 开启Stream流处理
            .map(user -> BeanUtil.copyProperties(user, UserDTO.class)) // ⑥ 将每个User实体转换为UserDTO
            .collect(Collectors.toList());              // ⑦ 收集为List
    // 4.返回
    return Result.ok(userDTOS);
}

//.last("ORDER BY FIELD(id," + idStr + ")")中的 last方法是MyBatis-Plus提供的方法。
// ​作用​：它将传入的字符串直接拼接到最终生成的SQL语句的末尾。

//stream()是Java 8引入的Stream API的起点方法。它将一个集合（比如 List<User>）转换成一条流（Stream）​
//它支持： 
//        链式操作（像 SQL 一样写条件、转换、排序等）； 
//        内部迭代（不需要自己写 for 循环，Stream 自己会帮你遍历）；
//        声明式编程（写“要做什么”，而不是写“怎么做”）
//​map​：是Stream的一个方法，意为“映射”或“转换”。它会把流中的每一个元素转换成另一个新的元素。
//.collect() 是 Java Stream API 里的一个 终端操作（terminal operation）。
//		它的作用是：把流（Stream）里的元素收集起来，转成一个结果容器（如 List、Set、Map，甚至拼接成字符串等）。
```

<font style="color:rgb(208, 199, 186);background-color:rgb(38, 42, 43);">这里的排行榜应该是按照点赞先后来排序的，但是按照</font><font style="color:rgb(107, 200, 255) !important;">mysql</font><font style="color:rgb(208, 199, 186);background-color:rgb(38, 42, 43);">的查询，会自动将查询的数据进行从小到大排序，这样不符合业务逻辑，这里可以使用</font>`<font style="color:rgb(255, 88, 132);background-color:rgb(50, 24, 31);">ORDER BY FIELD(id, 5, 1)</font>`<font style="color:rgb(208, 199, 186);background-color:rgb(38, 42, 43);">可以按照传出的参数进行排序，这样符合点赞排行的后赞排在前面，前赞排在后面。</font>

### Set 交并集功能实现共同关注
```java
@Override
public Result followCommons(Long id) {
    // 1.获取当前用户
    Long userId = UserHolder.getUser().getId();
    String key = "follows:" + userId;
    // 2.求交集
    String key2 = "follows:" + id;
    Set<String> intersect = stringRedisTemplate.opsForSet().intersect(key, key2);
    if (intersect == null || intersect.isEmpty()) {
        // 无交集
        return Result.ok(Collections.emptyList());
    }
    // 3.解析id集合
    List<Long> ids = intersect.stream().map(Long::valueOf).collect(Collectors.toList());
    // 4.查询用户
    List<UserDTO> users = userService.listByIds(ids)
            .stream()
            .map(user -> BeanUtil.copyProperties(user, UserDTO.class))
            .collect(Collectors.toList());
    return Result.ok(users);
}

```

### Feed流关注推送
> 关注推送也叫做Feed流，直译为投喂。为用户持续的提供“沉浸式”的体验，通过无限下拉刷新获取新的信息。Feed流通过算法和用户行为数据分析，动态地将用户感兴趣的内容以流式方式呈现在用户的界面上。
>

Feed流产品有两种常见模式：

时间排序（Timeline）：不做内容筛选，简单的按照内容发布时间排序，常用于好友或关注。例如朋友圈

优点：信息全面，不会有缺失。并且实现也相对简单

缺点：信息噪音较多，用户不一定感兴趣，内容获取效率低

智能排序：利用智能算法屏蔽掉违规的、用户不感兴趣的内容。推送用户感兴趣信息来吸引用户

优点：投喂用户感兴趣信息，用户粘度很高，容易沉迷

缺点：如果算法不精准，可能起到反作用

参考:[【Redis】6.Feed流_feed流 分页-CSDN博客](https://blog.csdn.net/weixin_51146329/article/details/127704318?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522168897045216800215044629%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=168897045216800215044629&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-127704318-null-null.142%5Ev88%5Econtrol_2,239%5Ev2%5Einsert_chatgpt&utm_term=feed%E6%B5%81&spm=1018.2226.3001.4187)
