---
title: VGG16
date: '2024-12-30 16:38:43'
updated: '2025-08-22 16:14:41'
---
![](/images/d5f618940e106e1364c47c1856b96aa5.png)

#### VGG贡献
证明了增加深度，神经网络性能更好。  
小卷积核串联可以获得与大卷积核相同的感受野。  
AlexNet中的局部响应归一化作用不明显。

网络结构

1、输入224x224x3的图片，经64个3x3的卷积核作两次卷积+ReLU，卷积后的尺寸变为224x224x64

2、作max pooling（最大化池化），池化单元尺寸为2x2（效果为图像尺寸减半），池化后的尺寸变为112x112x64

3、经128个3x3的卷积核作两次卷积+ReLU，尺寸变为112x112x128

4、作2x2的max pooling池化，尺寸变为56x56x128

5、经256个3x3的卷积核作三次卷积+ReLU，尺寸变为56x56x256

6、作2x2的max pooling池化，尺寸变为28x28x256

7、经512个3x3的卷积核作三次卷积+ReLU，尺寸变为28x28x512

8、作2x2的max pooling池化，尺寸变为14x14x512

9、经512个3x3的卷积核作三次卷积+ReLU，尺寸变为14x14x512

10、作2x2的max pooling池化，尺寸变为7x7x512

11、与两层1x1x4096，一层1x1x1000进行全连接+ReLU（共三层）

12、通过softmax输出1000个预测结果

## ![](/images/4aa76e9aa6c85b36a6619886d490d0f7.png)主要改进
### 输入去均值
AlexNet和ZFNet的输入去均值：求所有图像向量的均值，最后得出一个与原始图像大小相同维度的均值向量。

VGG输入去均值：求所有图像向量的RGB均值，最后得到的是一个3×1的向量 [R,G,B]



### 小卷积核串联代替大卷积核
增加了非线性能力。

多个小尺寸卷积核串联可以得到与大尺寸卷积核相同的感受野。

与高斯核不同，高斯核中两个小卷积核组合卷积和大卷积核卷积结果相同。但是卷积神经网络中的卷积核，多个小卷积核组合和大卷积核结果不同，但是感受野相同。

### 无重叠池化
窗口大小为2×2，步长为2。



### 卷积核个数逐层增加
前层卷积核少，是因为前层学习到的是图像的基元（点、线、边），基元很少，所以不需要很多的神经元学习，又前层的图像都比较大，若神经元很多，计算量会很大（K×m×m×D×K×n×n）。到后面的层时，包含很多的语义结构，需要更多的卷积核学习。![](/images/e4acf11a515274228d69c2f2d4404e1b.png)![](/images/a43d7a4b9c816350daaf064c5ebc1380.png)

全连接第一个隐层的参数个数：7×7× 512× 4096 = 102,760,448，卷积核个数增加到512就不能再增加。



