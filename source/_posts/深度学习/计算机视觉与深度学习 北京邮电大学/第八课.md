---
title: 第八课
date: '2024-07-16 16:22:08'
updated: '2025-08-21 16:18:38'
---
<font style="color:rgb(77, 77, 77);">上节复习（00：00-11：39）</font>

### <font style="color:rgb(79, 79, 79);">一、纹理表示</font>
#### <font style="color:rgb(79, 79, 79);">（一）纹理</font>
+ <font style="color:rgba(0, 0, 0, 0.75);">1.纹理：人脸也是纹理的一种。你可以理解为任何一种模式都可以称为纹理。</font>
+ <font style="color:rgba(0, 0, 0, 0.75);">2.纹理分为规则纹理和随即纹理。</font>
+ <font style="color:rgba(0, 0, 0, 0.75);">3.为识别纹理，引入一种</font>**<font style="color:rgba(0, 0, 0, 0.75);">基于卷积核组的纹理表示方法</font>**<font style="color:rgba(0, 0, 0, 0.75);">。</font>
    - <font style="color:rgba(0, 0, 0, 0.75);">3.1该方法 利用卷积核组提取图像中的纹理基 + 利用</font>**<font style="color:rgba(0, 0, 0, 0.75);">基元的统计信息</font>**<font style="color:rgba(0, 0, 0, 0.75);">来表示图像中的纹理。</font>

#### <font style="color:rgb(79, 79, 79);">（二）基于卷积核组的纹理表示方法</font>
+ <font style="color:rgba(0, 0, 0, 0.75);">1.先具一个实际的例子  
</font>![](/images/80919ffb537322ee72217126a80e29b3.png)<font style="color:rgba(0, 0, 0, 0.75);">  
</font><font style="color:rgba(0, 0, 0, 0.75);">注：实施上上图的“边缘”是高斯一阶偏导卷积核、“条状”是高斯二阶偏导卷积核。而神经网络的学习，就是学出很多这样带有不同特征的卷积核，而待检测图片与哪个学习后的卷积核最匹配，就强行认为图片是这一类。</font>
+ <font style="color:rgba(0, 0, 0, 0.75);">2.SS：我理解基于卷积核组的纹理表示方法。从上图可知，卷积核组是大量的卷积核，这些卷积核与原图卷积后，能够提取出一组对应的包含有边缘\条状\点状三种不同种类，和上图中给出的不同大小的特征的图片。根据一定的方法对上述特征图片进行排序（实际上是取均值后最大值），就一定能选举出最符合某种卷积核特征的模式。（既，基于卷积核组的纹理表示方法不是找到图片的纹理，而是对比图片与常见纹理的符合程度，强行认为最符合的常见纹理就是该图片具有的纹理。）</font>
+ <font style="color:rgba(0, 0, 0, 0.75);">3.所以，基于卷积核组的纹理表示方法步骤第一步是设计卷积核组：</font>
    - <font style="color:rgba(0, 0, 0, 0.75);">第一步：设计卷积核组</font>
    - <font style="color:rgba(0, 0, 0, 0.75);">第二步：利用卷积核组对图像进行卷积操作获得对应的特征响应图组</font>
    - <font style="color:rgba(0, 0, 0, 0.75);">第三步：利用特征响应图的某种统计信息来表示图像中的纹理</font>

#### <font style="color:rgb(79, 79, 79);">（三）在 基于卷积核组的纹理表示方法 和 卷积</font>[<font style="color:rgb(79, 79, 79);">神经网络</font>](https://so.csdn.net/so/search?q=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&spm=1001.2101.3001.7020)<font style="color:rgb(79, 79, 79);"> </font><font style="color:rgb(79, 79, 79);">之间要说明的一些问题</font>
+ <font style="color:rgba(0, 0, 0, 0.75);">1.为了更好的理解卷积神经网络，我们可以在理解上图和基于卷积核的纹理表示方法的基础上加深一点。</font>

<font style="color:rgb(77, 77, 77);">一个设计好的卷积核组（例如48个)和一张图片</font>![](/images/04ac232a5610e81497a714f54b082b29.png)<font style="color:rgb(77, 77, 77);">  
</font><font style="color:rgb(77, 77, 77);">经过卷积得到了48张特征相应图  
</font>![](/images/e3703f6e1cd5ba2b470bfea145a8b949.png)<font style="color:rgb(77, 77, 77);">  
</font><font style="color:rgb(77, 77, 77);">对第一张特征相应图，不妨按行展开为一个行向量，称之为r1；对其余特征图重复上述操作，得到行向量r1 —r48。（不妨设行向量有100项）将行向量按竖向排列，得到一个尺寸为48*100的矩阵。</font>

![](/images/d0f12fd02ce6ddb01e39c3c133c6fc97.png)

<font style="color:rgb(77, 77, 77);">取矩阵的第一列来看，其意义就是原图片的第一个像素，与48个卷积核卷积后得到的48个特征值。选择第一列中的最大值，就是图片在第一个像素位置所具有的最强的特征（但是这个特征是提前设计好的，若设计者没想到某种特征的卷积核，也必然无法识别到相应的特征）。  
</font><font style="color:rgb(77, 77, 77);">[a11,a21,a31,…,</font>**<font style="color:rgb(77, 77, 77);">a22</font>**<font style="color:rgb(77, 77, 77);">,…，a48 ] T (不妨认为a22是最靓的仔，则说明像素1最符合特征22。）</font>

<font style="color:rgb(77, 77, 77);">现在转换思维，假设48个卷积核组是经过训练后得到的成熟的分类网络，我们就能在48*100的矩阵中，找到100个最靓的仔，其中最靓的仔最多的一行，我们就可以按一定的几率猜测原图符合这个卷积核，既是这个卷积核代表的那一类。</font>

### <font style="color:rgb(79, 79, 79);">二、卷积神经网络</font>
#### <font style="color:rgb(79, 79, 79);">（一）全连接神经网络的瓶颈（运算量太大）</font>
+ <font style="color:rgba(0, 0, 0, 0.75);">1.对于全连接神经网络，如果一张输入图是CIFAR10的图像尺寸为32×32×3，隐层每个神经元权值的个数是多少个？答：32×32×3+1 = 3073个。 如果一张图大小200×200×3，隐层的每个神经元权值个数是多少？答：200×200×3+1 = 120001个。如果隐层有隐层有10个、20个甚至更多个神经元，那需要训练的权值个数将是不可接受的。</font>
+ <font style="color:rgba(0, 0, 0, 0.75);">2.但是如果我们用卷积核组，将一张图像卷积成48（不妨设为48）张特征图，每一张图取均值（不妨取均值，更高效和优秀的方法另学），就会得到48个均值，将均值组合在一起形成48维向量，以这个48维向量作为输入，隐层的神经元权值个数就只有49个，就非常好训练了。  
</font>![](/images/d006fdb15e415f8b790f55aa3bede2d4.png)

#### <font style="color:rgb(79, 79, 79);">（二）卷积神经网络（一个缝合怪）</font>
+ <font style="color:rgba(0, 0, 0, 0.75);">1.</font>**<font style="color:rgba(0, 0, 0, 0.75);">将卷积核组作为一层，和全连接神经网络拼接在一起，就形成了卷积神经网络。</font>**
+ <font style="color:rgba(0, 0, 0, 0.75);">2.通常一个卷积神经网络有如下部分组成  
</font>![](/images/8834876161f9b74f1007b842fb14c30b.png)
+ <font style="color:rgba(0, 0, 0, 0.75);">2.1前部是大量的卷积层、激活层、池化层，这些层将图像从（不妨设）200×200×3个像素大小，提取特征变为（不妨设）48维的向量，再由全连接层去识别。</font>
+ <font style="color:rgba(0, 0, 0, 0.75);">3.卷积操作的计算过程：  
</font>![](/images/062c6fb7d38006da100092c7cd7667cc.png)
    - <font style="color:rgba(0, 0, 0, 0.75);">3.1 注：看到“卷积核是5×5×3”时不要理解错误，这里所描述的是卷积核是一个5×5×3=75维的向量空间，该卷积核可以写为一个1×75的行向量，同理图片中与卷积核卷积的像素也要展开成1×75的行向量。之后进行点乘操作，变成一个数，在进行偏置。这是就得到原图中的某一个像素点，在现有卷积核下的特征值。</font>
    - <font style="color:rgba(0, 0, 0, 0.75);">3.2 用现有卷积核划过整张图片，得到</font>**<font style="color:rgba(0, 0, 0, 0.75);">一张特征图</font>**<font style="color:rgba(0, 0, 0, 0.75);">。用不同卷积核划过这张图片，得到</font>**<font style="color:rgba(0, 0, 0, 0.75);">带有深度的特征响应图组</font>**<font style="color:rgba(0, 0, 0, 0.75);">。（PS下图特征图为28*28因为没有边界填充）不妨设使用了6个卷积核得到了H =28,W=28,D=6的图。</font>
    - ![](/images/61e47005ffbab1c03c5db64b23622a45.png)
    - <font style="color:rgba(0, 0, 0, 0.75);">3.3</font>**<font style="color:rgba(0, 0, 0, 0.75);"> 通常卷积层是叠加的</font>**<font style="color:rgba(0, 0, 0, 0.75);">，既上述卷积层输出的28×28×6的图会作为输入，输入下一个卷积层。那么，问题是</font>**<font style="color:rgba(0, 0, 0, 0.75);">下一个卷积层的卷积核尺寸如何设计？答：设计为H×W×6</font>**<font style="color:rgba(0, 0, 0, 0.75);">。既H高度和W宽度需要自行设计，但是D深度必定等于6，既深度由上一层的卷积层的卷积核个数决定。</font>
+ <font style="color:rgba(0, 0, 0, 0.75);">4.卷积步长：卷积神经网络中，卷积核可以按照指定的间隔进行卷积操作，这个间隔就是</font>**<font style="color:rgba(0, 0, 0, 0.75);">卷积步长</font>**<font style="color:rgba(0, 0, 0, 0.75);">。</font>
+ **<font style="color:rgba(0, 0, 0, 0.75);">5.特征响应图组尺寸的计算</font>**<font style="color:rgba(0, 0, 0, 0.75);">  
</font>![](/images/dff3736501d407ee3f0c93bc3fdbcdda.png)

#### <font style="color:rgb(79, 79, 79);">（三）卷积神经网络的新组成部分—池化操作</font>
![](/images/40888eab0d3e99149900093c7abeef94.png)

![](/images/7acf3990ed7ade6e895b176b8024323c.png)

![](/images/f899b33c861707c72567ee21d9b2150b.png)		

+ <font style="color:rgba(0, 0, 0, 0.75);">1.池化的作用：</font>
    - <font style="color:rgba(0, 0, 0, 0.75);">计算量：对每一个特征响应图独立进行，</font>**<font style="color:rgba(0, 0, 0, 0.75);">降低</font>**<font style="color:rgba(0, 0, 0, 0.75);">特征响应图组中每个特征响应图的</font>**<font style="color:rgba(0, 0, 0, 0.75);">宽度和高度</font>**<font style="color:rgba(0, 0, 0, 0.75);">，减少后续卷积层的参数数量，降低计算资源耗费，进而控制过拟合。</font>

![](/images/96b39a2396785752f4dfedd318551ecb.png)

注：因为每次卷积后的图组都会存在显存，用于反向传递

    - <font style="color:rgba(0, 0, 0, 0.75);">观察尺度：让卷积核看到图片上的更大视野（增大感受野）</font>

![](/images/ec0c3fe57a4527529a6b022ad7a10564.png)

+ <font style="color:rgba(0, 0, 0, 0.75);">2.池化操作：对特征响应图</font><font style="color:#DF2A3F;">某个区域</font><font style="color:rgba(0, 0, 0, 0.75);">进行池化就是在该区域上</font><font style="color:#DF2A3F;">指定一个值来代表整个区域</font><font style="color:rgba(0, 0, 0, 0.75);">。----类似非最大化抑制</font>

![](/images/d78e68dc9dd97b65fadf0e50c090753d.png)

+ <font style="color:rgba(0, 0, 0, 0.75);">3.常见的池化操作：</font>

:::info
思想就是希望用最大值保留区域主要的特征，尽可能保留区域信息

:::

    - <font style="color:rgba(0, 0, 0, 0.75);">最大池化—使用区域内的最大值来代表这个区域；</font>
    - <font style="color:rgba(0, 0, 0, 0.75);">平均池化—采用区域内所有值的平均值作为代表。</font>
+ <font style="color:rgba(0, 0, 0, 0.75);">4.池化层的超参数：池化窗口和池化步长。</font>
    - <font style="color:rgba(0, 0, 0, 0.75);">有重叠的池化</font>
    - <font style="color:rgba(0, 0, 0, 0.75);">没重叠的池化</font>

#### <font style="color:rgb(79, 79, 79);">（四）再回到卷积神经网络</font>
![](/images/13084c853ebca7cdd32727ed8a95722e.png)

+ <font style="color:rgba(0, 0, 0, 0.75);">1.仔细思考思考从最后一个POOL层出来的是什么？既提交给FC的是什么？可以是什么？</font>
+ <font style="color:rgba(0, 0, 0, 0.75);">2.可以将特征图组以10个向量的形式提交给FC。也可以将每个向量求平均值，组合为一个10维的由平均值构成的向量，提交给FC。</font>

 	向量：每个位置的特征响应信息		     			均值：图片对该基元响应的强弱

![](/images/53884edbffa815da1257863b2e08f9c5.png)

从纹理角度理解卷积层：

### <font style="color:rgb(79, 79, 79);">三、损失函数&优化算法</font>
+ <font style="color:rgba(0, 0, 0, 0.75);">1.损失函数：用交叉熵损失</font>
+ <font style="color:rgba(0, 0, 0, 0.75);">2.优化算法：SGD、带动量的SGD以及</font>**<font style="color:rgba(0, 0, 0, 0.75);">ADAM</font>**

### <font style="color:rgb(79, 79, 79);">四、训练过程</font>
+ <font style="color:rgba(0, 0, 0, 0.75);">1.原先的批归一化、权值初始化策略都要用，但是这里不讲了</font>

#### <font style="color:rgb(79, 79, 79);">（一）样本增强（图像增强）</font>
+ <font style="color:rgba(0, 0, 0, 0.75);">1.存在问题：过拟合的原因是学习样本太少，导致无法训练出能够泛化到新数据集的模型。（之前讲过解决方法：L1\L2正则化、控制权重、dropout等）</font>
+ <font style="color:rgba(0, 0, 0, 0.75);">2.数据增强：是从现有的训练样本中生成更多的训练数据，其方法是利用多种能够生成可信图像的随即变换来增减样本。（比如镜像、随即缩放、裁剪、色彩抖动）</font>

